{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## Pima Diabetes Dataset\n",
    "\n",
    "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
    "\n",
    "seed_value = 11111\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0.364</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.265</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.431</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.699</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "8                 2                     197              70              45   \n",
       "681               0                     162              76              36   \n",
       "724               1                     111              94               0   \n",
       "213               0                     140              65              26   \n",
       "593               2                      82              52              22   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "8        543  30.5              0.158   53             1  \n",
       "681        0  49.6              0.364   26             1  \n",
       "724        0  32.8              0.265   45             0  \n",
       "213      130  42.6              0.431   24             1  \n",
       "593      115  28.5              1.699   25             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=11111)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=seed_value)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771, roc-auc is 0.795\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}, roc-auc is {:.3f}'.format(\n",
    "    accuracy_score(y_test, y_pred_class_rf), roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAK9CAYAAADPDR+cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAACOGklEQVR4nOzdd3gU1cPF8ZNe6EgVIlVBBEFBEBRRaVJFQUIvIqCACgHpvSNIb4JUKQldpXcURVGKgjRpIi0QWkhC6s77hz/2NSSBbEgym93v53l4dCczuye52eTk7t0ZF8MwDAEAAAAOwtXsAAAAAEBqouACAADAoVBwAQAA4FAouAAAAHAoFFwAAAA4FAouAAAAHAoFFwAAAA6FggsAAACHQsEFAACAQ6HgAkh348ePV9GiReXm5qZy5cqZHQcmGjp0qFxcXOJtK1y4sNq1a2fzfe3evVsuLi5atWpVKqVzHu3atVPmzJmTta+Li4uGDh2atoGAx0TBhdNZuHChXFxcrP/c3d1VoEABtWvXTpcuXUr0GMMw9PXXX+u1115T9uzZ5evrqzJlymj48OEKDw9P8rHWrl2rOnXqKFeuXPL09NSTTz6ppk2baufOncnKGhkZqUmTJqlSpUrKli2bvL299cwzz6hbt246depUij5/s23dulW9e/fWK6+8ogULFmj06NFp+njt2rWLN95eXl565plnNHjwYEVGRibY/7/7/vdfvnz50jRncj34/fvf74ng4GDrfomVvf8eu3fv3gT3bRiG/Pz85OLiovr16yf6+Ldv35a3t7dcXFx0/Pjx1P8E7cxPP/2koUOH6vbt22ZHAWADd7MDAGYZPny4ihQposjISP38889auHCh9u7dq6NHj8rb29u6X1xcnFq0aKEVK1aoatWqGjp0qHx9ffXDDz9o2LBhWrlypbZv3668efNajzEMQ++//74WLlyoF154QQEBAcqXL5+uXLmitWvXqnr16vrxxx9VpUqVJPOFhITorbfe0oEDB1S/fn21aNFCmTNn1smTJxUYGKg5c+YoOjo6Tb9GaWHnzp1ydXXVvHnz5OnpmS6P6eXlpa+++kqSdOfOHX3zzTcaMWKEzpw5o6VLlybYv2bNmmrTpk28bT4+PumSNbn++/27d+9ezZo1Sxs3btTRo0fl6+v70GO9vb21bNkyvfrqq/G279mzRxcvXpSXl1eSx65cudJa+JcuXaqRI0emyufzXydPnpSrq33Mv/z0008aNmyY2rVrp+zZs5sdB0ByGYCTWbBggSHJ+PXXX+Nt79OnjyHJCAoKird99OjRhiSjV69eCe7r22+/NVxdXY233nor3vbx48cbkozu3bsbFoslwXGLFy82fvnll4fmrFevnuHq6mqsWrUqwcciIyONnj17PvT45IqJiTGioqJS5b6So3379kamTJlS7f4sFosRERGR5Mfbtm2b4PEsFovx8ssvGy4uLsbVq1fjfUyS0bVr11TLl9qS+v4NCAgwJBnLli0zDMMwdu3aZUgyVq5cmeDYd99918iVK5cRExMT7z46duxolC9f3ihUqJBRr169RB//tddeM959912jR48eRpEiRR778xkyZIiRWr+KEvucH9f95/K5c+dS7T7Tw71794y4uLhk75/Y8yQpkowhQ4akMBmQPuzjT2TADlStWlWSdObMGeu2e/fuafz48XrmmWc0ZsyYBMc0aNBAbdu21ebNm/Xzzz9bjxkzZoxKliypCRMmJFhfKEmtW7dWxYoVk8zyyy+/aMOGDerQoYMaN26c4ONeXl6aMGGC9fbrr7+u119/PcF+7dq1U+HCha23z58/LxcXF02YMEGTJ09WsWLF5OXlpUOHDsnd3V3Dhg1LcB8nT56Ui4uLpk+fbt12+/Ztde/eXX5+fvLy8lLx4sU1btw4WSyWJD8n6d+X/xcsWKDw8HDrS+ULFy6UJMXGxmrEiBHWTIULF1b//v0VFRUV7z4KFy6s+vXra8uWLapQoYJ8fHz05ZdfPvRxE8vx6quvyjAMnT171qZjH+bs2bN67733lDNnTvn6+urll1/Whg0b4u1zf+nAihUrNGrUKBUsWFDe3t6qXr26Tp8+neLHfvPNNyVJ586de+S+zZs3140bN7Rt2zbrtujoaK1atUotWrRI8rgLFy7ohx9+ULNmzdSsWTOdO3dOP/30U7Iz7t27Vy+99JK8vb1VrFixJMftwTW4N2/eVK9evVSmTBllzpxZWbNmVZ06dfT7778nenxcXJz69++vfPnyKVOmTGrYsKH++eefBPv98ssveuutt5QtWzb5+vqqWrVq+vHHH60fHzp0qD777DNJUpEiRazfs+fPn7fus2TJEpUvX14+Pj7KmTOnmjVrluCx/vrrLzVu3Fj58uWTt7e3ChYsqGbNmunOnTsP/Xq9/vrrKl26tA4cOKAqVarIx8dHRYoU0ezZs+Ptd/97KjAwUAMHDlSBAgXk6+ur0NBQSf/Out/PmCtXLrVq1SrJ5Vhnz55V7dq1lSlTJj355JMaPny4DMN4aE5JunTpkt5//33lzZtXXl5eeu655zR//vxEc65YsULDhg1TgQIFlCVLFjVp0kR37txRVFSUunfvrjx58ihz5sxq3759guc/kFwsUQD+5/4vrRw5cli37d27V7du3dKnn34qd/fEny5t2rTRggULtH79er388svau3evbt68qe7du8vNzS1FWb799ltJ/xbhtLBgwQJFRkaqU6dO8vLyUv78+VWtWjWtWLFCQ4YMibdvUFCQ3Nzc9N5770mSIiIiVK1aNV26dEmdO3fWU089pZ9++kn9+vXTlStXNHny5CQf9+uvv9acOXO0f/9+65KB+8s0PvjgAy1atEhNmjRRz5499csvv2jMmDE6fvy41q5dG+9+Tp48qebNm6tz587q2LGjSpQoYfPXILHxvi8yMlIhISHxtmXJkuWhL90HBwerSpUqioiI0CeffKInnnhCixYtUsOGDbVq1Sq988478fYfO3asXF1d1atXL925c0eff/65WrZsqV9++cXmz0X6/z/MnnjiiUfuW7hwYVWuXFnLly9XnTp1JEmbNm3SnTt31KxZM02dOjXR45YvX65MmTKpfv368vHxUbFixbR06dKHLrW578iRI6pVq5Zy586toUOHKjY2VkOGDIm3tCcpZ8+e1bp16/Tee++pSJEiCg4O1pdffqlq1arp2LFjevLJJ+PtP2rUKLm4uKhPnz66du2aJk+erBo1aujw4cPWpSY7d+5UnTp1VL58eQ0ZMkSurq5asGCB3nzzTf3www+qWLGi3n33XZ06dUrLly/XpEmTlCtXLklS7ty5rY8zaNAgNW3aVB988IGuX7+uadOm6bXXXtOhQ4eUPXt2RUdHq3bt2oqKitLHH3+sfPny6dKlS1q/fr1u376tbNmyPfRzv3XrlurWraumTZuqefPmWrFihT766CN5enrq/fffj7fviBEj5OnpqV69eikqKkqenp5auHCh2rdvr5deekljxoxRcHCwpkyZoh9//NGa8b64uDi99dZbevnll/X5559r8+bNGjJkiGJjYzV8+PAkMwYHB+vll1+Wi4uLunXrpty5c2vTpk3q0KGDQkND1b1793j7jxkzRj4+Purbt69Onz6tadOmycPDQ66urrp165aGDh1qXTZWpEgRDR48+KFfIyBRZk8hA+nt/su027dvN65fv278888/xqpVq4zcuXMbXl5exj///GPdd/LkyYYkY+3atUne382bN60v+xqGYUyZMuWRxzzKO++8Y0gybt26laz9q1WrZlSrVi3B9rZt2xqFChWy3j537pwhyciaNatx7dq1ePt++eWXhiTjyJEj8baXKlXKePPNN623R4wYYWTKlMk4depUvP369u1ruLm5GRcuXHho1sReCj18+LAhyfjggw/ibe/Vq5chydi5c6d1W6FChQxJxubNmx/6OA8+3vXr143r168bp0+fNiZMmGC4uLgYpUuXTrCERFKi/xYsWPDQx+nevbshyfjhhx+s2+7evWsUKVLEKFy4sPXl4vsvoz/77LPxlobc/7558Ov/oMS+fwMDA40nnnjC8PHxMS5evBjvcRJbovDrr78a06dPN7JkyWJd3vHee+8Zb7zxhmEYRpJLFMqUKWO0bNnSert///6JLnVITKNGjQxvb2/j77//tm47duyY4ebmlmCJQqFChYy2bdtab0dGRiZ4uf3cuXOGl5eXMXz4cOu2+59zgQIFjNDQUOv2FStWGJKMKVOmGIbx7xKVp59+2qhdu3a88Y+IiDCKFCli1KxZ07otqSUK58+fN9zc3IxRo0bF237kyBHD3d3duv3QoUMpXjZRrVo1Q5LxxRdfWLdFRUUZ5cqVM/LkyWNER0fH+7yLFi0ab7lOdHS0kSdPHqN06dLGvXv3rNvXr19vSDIGDx5s3da2bVtDkvHxxx9bt1ksFqNevXqGp6encf36det2PbBEoUOHDkb+/PmNkJCQePmbNWtmZMuWzZrpfs7SpUtbsxuGYTRv3txwcXEx6tSpE+/4ypUrx/v5BdiCJQpwWjVq1FDu3Lnl5+enJk2aKFOmTPr2229VsGBB6z53796V9O/sXVLuf+z+y4H3//uwYx4lNe7jYRo3bmydhbrv3Xfflbu7u4KCgqzbjh49qmPHjsnf39+6beXKlapatapy5MihkJAQ678aNWooLi5O33//vc15Nm7cKEkKCAiIt71nz56SlOBl/iJFiqh27drJvv/w8HDlzp1buXPnVvHixdWrVy+98sor+uabbxJdQvL2229r27Zt8f496vE2btyoihUrxnvjVubMmdWpUyedP39ex44di7d/+/bt473J7v4SmeQumfjv92+zZs2UOXNmrV27VgUKFEjW8U2bNtW9e/e0fv163b17V+vXr3/o8oQ//vhDR44cUfPmza3bmjdvrpCQEG3ZsuWhjxUXF6ctW7aoUaNGeuqpp6zbn3322WSNo5eXl/VNZ3Fxcbpx44YyZ86sEiVK6ODBgwn2b9OmTbznTpMmTZQ/f37r99nhw4f1119/qUWLFrpx44b1ezg8PFzVq1fX999//8jlNmvWrJHFYlHTpk3jPQ/y5cunp59+Wrt27ZIk6wztli1bFBER8cjP9UHu7u7q3Lmz9banp6c6d+6sa9eu6cCBA/H2bdu2bbw3Q/7222+6du2aunTpEu+Ns/Xq1VPJkiUTPK8kqVu3btb/vz8jGx0dre3btyeazzAMrV69Wg0aNJBhGPG+FrVr19adO3cSjFGbNm3k4eFhvV2pUiXrG3P/q1KlSvrnn38UGxv7sC8RkCiWKMBpzZgxQ88884zu3Lmj+fPn6/vvv0/wEvT9X5L3i25iHizBWbNmfeQxj/Lf+0iLd24XKVIkwbZcuXKpevXqWrFihUaMGCHp3+UJ7u7uevfdd637/fXXX/rjjz8SFOT7rl27ZnOev//+W66uripevHi87fny5VP27Nn1999/PzL/w3h7e+u7776TJF28eFGff/65rl27luSZEQoWLKgaNWrY9Bh///23KlWqlGD7s88+a/146dKlrdv/W/Sk/18qcevWrWQ93v3vX3d3d+XNm1clSpSw6cwDuXPnVo0aNbRs2TJFREQoLi5OTZo0SXL/JUuWKFOmTCpatKh1rbC3t7cKFy6spUuXql69ekkee/36dd27d09PP/10go+VKFHCWjyTYrFYNGXKFM2cOVPnzp1TXFyc9WOJLcl48HFcXFxUvHhx67KUv/76S9K/hTApd+7cSXT5yn1//fWXDMNI9HOSZC1wRYoUUUBAgCZOnKilS5eqatWqatiwoVq1avXI5QmS9OSTTypTpkzxtj3zzDOS/l1m8/LLL1u3P/i8uP+8SWwJT8mSJROcKs7V1VVFixZN8rESc/36dd2+fVtz5szRnDlzEt3nwZ8JD37v3/86+Pn5JdhusVh0586dZC29Af6LggunVbFiRVWoUEGS1KhRI7366qtq0aKFTp48aT3h+f1y8scff6hRo0aJ3s8ff/whSSpVqpSkf39xSP+uOUzqmEf5733cn9l7GBcXl0TfCPLfIvBfSRW7Zs2aqX379jp8+LDKlSunFStWqHr16ta1h9K/ZaNmzZrq3bt3ovdx/xdiSiQ2m5oYW0/Z5ebmFq+w1q5dWyVLllTnzp2t653TW1LrsxMbx8T89/s3pVq0aKGOHTvq6tWrqlOnTpJ/TBmGoeXLlys8PNz6ff5f165dU1hYWLIvFGCr0aNHa9CgQXr//fc1YsQI5cyZU66ururevfsjZ1oTc/+Y8ePHJ3mhkUd9LhaLRS4uLtq0aVOiY/nf47/44gu1a9dO33zzjbZu3apPPvlEY8aM0c8//xzvFaPHZcap7O5/LVu1apXkHwzPP/98vNtJfe8/7nMC+C8KLqB/f7COGTNGb7zxhqZPn66+fftKkl599VVlz55dy5Yt04ABAxL9Abx48WJJsp4Y/9VXX1WOHDm0fPly9e/fP0VvNGvQoIHGjBmjJUuWJKvg5siRI9GXth+c+XyURo0aqXPnztZlCqdOnVK/fv3i7VOsWDGFhYXZPMP5MIUKFZLFYtFff/1l/aNC+vfNK7dv31ahQoVS7bEkKX/+/OrRo4eGDRumn3/+Od4sWEoVKlRIJ0+eTLD9xIkT1o/bm3feeUedO3fWzz//HG9pyoPunx93+PDh8cZH+nfGuVOnTlq3bp1atWqV6PG5c+eWj4+Pdeb0vxL7mj1o1apVeuONNzRv3rx422/fvh3vj6/7HnwcwzB0+vRpa9EqVqyYpH9fKXnU93FSf3QVK1ZMhmGoSJEiyfqjrkyZMipTpowGDhyon376Sa+88opmz579yPMIX758WeHh4fFmce9f5OW/Z0hJzP3vuZMnT1rPsnHfyZMnE3xPWiwWnT17Nt7n86jHyp07t7JkyaK4uLhU/ZkAPC7W4AL/8/rrr6tixYqaPHmy9QpXvr6+6tWrl06ePKkBAwYkOGbDhg1auHChateubS1Jvr6+6tOnj44fP64+ffokOvuwZMkS7d+/P8kslStX1ltvvaWvvvpK69atS/Dx6Oho9erVy3q7WLFiOnHihK5fv27d9vvvv8c75VFyZM+eXbVr19aKFSsUGBgoT0/PBLPQTZs21b59+xJdd3n79u0UrZerW7euJCU4A8PEiRMl6aEvf6fUxx9/LF9fX40dOzZV7q9u3brav3+/9u3bZ90WHh6uOXPmqHDhwonOfJotc+bMmjVrloYOHaoGDRokud/95QmfffaZmjRpEu9fx44d9fTTTyd6wYz73NzcVLt2ba1bt04XLlywbj9+/Pgj1+/eP/7B59HKlSuTPNXV4sWL4y0RWrVqla5cuWI9Y0T58uVVrFgxTZgwQWFhYQmO/+/z6H6xfPBKZu+++67c3Nw0bNiwBNkMw9CNGzck/bue/sHnRJkyZeTq6pqsU2DFxsbGO51adHS0vvzyS+XOnVvly5d/6LEVKlRQnjx5NHv27HiPtWnTJh0/fjzR59V/TwdoGIamT58uDw8PVa9ePdHHcHNzU+PGjbV69WodPXo0wcf/+7UE0hMzuMB/fPbZZ3rvvfe0cOFCffjhh5Kkvn376tChQxo3bpz27dunxo0by8fHR3v37tWSJUv07LPPatGiRQnu588//9QXX3yhXbt2qUmTJsqXL5+uXr2qdevWaf/+/Y88f+jixYtVq1Ytvfvuu2rQoIGqV6+uTJky6a+//lJgYKCuXLliPRfu+++/r4kTJ6p27drq0KGDrl27ptmzZ+u5556zvmEtufz9/dWqVSvNnDlTtWvXTvCy9WeffaZvv/1W9evXV7t27VS+fHmFh4fryJEjWrVqlc6fP5/orNrDlC1bVm3bttWcOXN0+/ZtVatWTfv379eiRYvUqFEjvfHGGzbdX3I88cQTat++vWbOnKnjx48nmJm0Vd++fa2n3frkk0+UM2dOLVq0SOfOndPq1avt5spcD3rYOlRJioqK0urVq1WzZs14b1T6r4YNG2rKlCm6du2a8uTJk+g+w4YN0+bNm1W1alV16dJFsbGxmjZtmp577jnrMp+k1K9fX8OHD1f79u1VpUoVHTlyREuXLk2wXvS+nDlz6tVXX1X79u0VHBysyZMnq3jx4urYsaOkf9eafvXVV6pTp46ee+45tW/fXgUKFNClS5e0a9cuZc2a1bpm+36JHDBggJo1ayYPDw81aNBAxYoV08iRI9WvXz+dP39ejRo1UpYsWXTu3DmtXbtWnTp1Uq9evbRz505169ZN7733np555hnFxsbq66+/thbDR3nyySc1btw4nT9/Xs8884yCgoJ0+PBhzZkzJ94btRLj4eGhcePGqX379qpWrZqaN29uPU1Y4cKF1aNHj3j7e3t7a/PmzWrbtq0qVaqkTZs2acOGDerfv3+Sa+6lf095t2vXLlWqVEkdO3ZUqVKldPPmTR08eFDbt2/XzZs3H/l5AqnOhDM3AKZK6kpQhmEYcXFxRrFixYxixYoZsbGx8bYvWLDAeOWVV4ysWbMa3t7exnPPPWcMGzbMCAsLS/KxVq1aZdSqVcvImTOn4e7ubuTPn9/w9/c3du/enaysERERxoQJE4yXXnrJyJw5s+Hp6Wk8/fTTxscff2ycPn063r5LliwxihYtanh6ehrlypUztmzZkuRpwsaPH5/kY4aGhho+Pj6GJGPJkiWJ7nP37l2jX79+RvHixQ1PT08jV65cRpUqVYwJEybEO/1PYpK6YlJMTIwxbNgwo0iRIoaHh4fh5+dn9OvXz4iMjIy338OusmXL4xmGYZw5c8Zwc3OLd0oqPcaVzM6cOWM0adLEyJ49u+Ht7W1UrFjRWL9+fbx9krra1v2xedTpyB72/fuox0nusf/9Gq9evdqQZMybNy/J/Xfv3h3vNFxJ2bNnj1G+fHnD09PTKFq0qDF79uxEr2SW2GnCevbsaeTPn9/w8fExXnnlFWPfvn0JTo93/3Nevny50a9fPyNPnjyGj4+PUa9evXinJ7vv0KFDxrvvvms88cQThpeXl1GoUCGjadOmxo4dO+LtN2LECKNAgQKGq6trglOGrV692nj11VeNTJkyGZkyZTJKlixpdO3a1Th58qRhGIZx9uxZ4/333zeKFStmeHt7Gzlz5jTeeOMNY/v27Q/9WhnGv6cJe+6554zffvvNqFy5suHt7W0UKlTImD59erz9HnUFt6CgIOOFF14wvLy8jJw5cxotW7a0nk7uvvvPkzNnzhi1atUyfH19jbx58xpDhgxJcIo2JXIls+DgYKNr166Gn5+f4eHhYeTLl8+oXr26MWfOnEfmTOr78v73xn9PUQYkl4thsHobAAB78/rrryskJCTRl/4BPJx9vmYGAAAApBAFFwAAAA6FggsAAACHwhpcAAAAOBRmcAEAAOBQKLgAAABwKE53oQeLxaLLly8rS5Ysyb7uPQAAANKPYRi6e/eunnzyyRRdKMfpCu7ly5fl5+dndgwAAAA8wj///KOCBQvafJzTFdwsWbJI+vcLljVrVuv2mJgYbd26VbVq1Xrk5Q+RcTHOjo8xdg6Ms3NgnB1fUmMcGhoqPz8/a2+zlakF9/vvv9f48eN14MABXblyRWvXrlWjRo0eeszu3bsVEBCgP//8U35+fho4cKDatWuX7Me8vywha9asCQqur6+vsmbNypPIgTHOjo8xdg6Ms3NgnB3fo8Y4pctJTX2TWXh4uMqWLasZM2Yka/9z586pXr16euONN3T48GF1795dH3zwgbZs2ZLGSQEAAJBRmDqDW6dOHdWpUyfZ+8+ePVtFihTRF198IUl69tlntXfvXk2aNEm1a9dOq5gAACCN/fnnn/rnn3/ibYuNjdXBgwfl5uYmd3enW1XpFO6P8csvv6y8efOm2v1mqO+Wffv2qUaNGvG21a5dW927d0/ymKioKEVFRVlvh4aGSvp3SjwmJsa6/f7//3cbHA/j7PgYY+fAODsOwzA0atQoDR8+3OwoMNErr7yiN954w3r7cZ/bGargXr16NUG7z5s3r0JDQ3Xv3j35+PgkOGbMmDEaNmxYgu1bt26Vr69vgu3btm1LvcCwW4yz42OMnQPjnLFZLBbNnz9f69evlyQVKlRIbm5uJqdCeomOjtaNGzeUL18+HT16VPfu3bN+LCIi4rHuO0MV3JTo16+fAgICrLfvvyuvVq1aCd5ktm3bNtWsWZOF7A6McXZ8jLFzYJwzvpiYGHXq1MlabidOnKhu3bol2IdxdkzR0dFq0qSJpk+frqNHjyYY4/uvuKdUhiq4+fLlU3BwcLxtwcHBypo1a6Kzt5Lk5eUlLy+vBNs9PDwSfbIktR2OhXF2fIyxc2CcM6Z79+6pWbNm+u677+Tm5qYFCxaodevWSe7PODuWEydOKDQ0VOvXr5fFYtHRo0cTjPHjjneGulRv5cqVtWPHjnjbtm3bpsqVK5uUCAAA2CI0NFR16tTRd999Jy8vL61du/ah5RaO5cSJE+rataueeuqpNF2OYmrBDQsL0+HDh3X48GFJ/54G7PDhw7pw4YKkf5cXtGnTxrr/hx9+qLNnz6p37946ceKEZs6cqRUrVqhHjx5mxAcAADa4fv263njjDe3Zs0dZs2bVli1b1KBBA7NjIZ0YhqFDhw5p2bJlypcvX5o+lqlLFH777bd475i7v1a2bdu2Wrhwoa5cuWItu5JUpEgRbdiwQT169NCUKVNUsGBBffXVV5wiDAAAO3fhwgXVrFlTp06dUu7cubV582a9+OKLZsdCOvnzzz81ZcoUzZkzJ10ez9SC+/rrr8swjCQ/vnDhwkSPOXToUBqmAgAAqenEiROqWbOmLl68qKeeekrbtm3TM888Y3YspJPz58/r008/1bJly9LtMTPUm8wAAIB9iI6O1r59+x55vtJbt26pS5cuCgkJUcmSJbV161b5+fmlU0qY7dSpU8qfP79WrFihnDlzptvjUnABAIDNunXrprlz5yZ7/woVKmjTpk3KlStXGqaCPTly5Ih69OihwMDAdB93Ci4AALDZ+fPnJUl+fn7KkSPHQ/d98cUXNXXqVGXJkiUdksFeLFq0yJRyK1FwAQDAYxg9erRatWpldgzYkd9//12//PKLJkyYYFqGDHUeXAAAANivw4cP67PPPlPjxo1NzcEMLgAAAB7bnTt35O3trcDAwHR9Q1limMEFAADAYzlw4ICaNWum4sWLm15uJQouAAAAHkN4eLiGDh2qZcuWyd3dPhYH2EcKAAAAZDi//vqr3N3d9c0338jV1X7mTSm4AAA4sVOnTunSpUs2H3fz5s00SIOMZP/+/Ro8eLCCgoLsqtxKFFwAAJzW4cOH9cILLzzWfdhbsUH6MAxDp0+fVlBQkLJly2Z2nAQouAAAOKn7F2vw9vZW0aJFbT4+X758ql69eiqngr37+eeftWTJEk2fPt3sKEmi4AIA4ORefPFF/fjjj2bHQAZw7NgxDRs2TEFBQWZHeSheVwAAAMAj/fHHH3rqqae0YsUKZc2a1ew4D0XBBQAAwEP9+OOP6tu3rwzDUJYsWcyO80gsUQAAAECSDMPQ2rVrtWLFCmXOnNnsOMlCwQUAAECifvjhB509e1YTJkwwO4pNWKIAAACABL7//nuNGzdOjRs3NjuKzZjBBQAAQDw3btxQnjx5FBQUpEyZMpkdx2bM4AIA4IQMw9DevXslcbEGxLdr1y517NhRJUqUyJDlVmIGFwAAp2OxWNSzZ09NnjxZktSyZUtzA8Fu3Lx5U9OnT9eSJUvk4uJidpwUo+ACAOBEYmNj9cEHH2jRokWSpEmTJunDDz80ORXswc6dO5UvXz6tWrUqQ5dbiSUKAAA4jcjISDVp0kSLFi2Sm5ubFi1apO7du5sdC3Zg+/btmjp1qooUKZLhy63EDC4AAE4hNDRUb7/9tnbv3i0vLy+tWLFCDRs2NDsW7IDFYtH169e1fPly+fj4mB0nVVBwAQBwcNevX1edOnV04MABZcmSRd9++61ef/11s2PBDmzZskXbt2/X+PHjzY6Sqii4AAA4sAsXLqhWrVo6efKkcuXKpc2bN6t8+fJmx4Id+PXXX/Xll19q2bJlZkdJdRRcAAAc1IkTJ1SzZk1dvHhRfn5+2rp1q0qWLGl2LNiBX375Rc8995yWLVsmb29vs+OkOgouAADJEB0drYMHD8pisZgdJVlCQkLUoUMHhYSEqESJEtq6daueeuops2PBDmzcuFHz58/X0qVL5eXlZXacNEHBBQAgGVq3bq0VK1aYHcNm5cuX16ZNm5Q7d26zo8AOxMXF6fvvv3focitRcAEASJa//vpLkpQvX74Mc3WnSpUqadasWcqaNavZUWAHvvvuO0VERGjs2LFmR0lzFFwAAGywYMECvfXWW2bHAGyyfv16LVmyRF9//bXZUdIFF3oAAABwYMHBwXr66af19ddfy9PT0+w46YKCCwAA4KDWrl2rXr16qUSJEk5TbiUKLgAAgEO6cuWK1qxZo/nz55sdJd1RcAEAABzM2rVrFR4ersWLF8vDw8PsOOmOggsAAOBAVq5cqdWrV6tw4cJycXExO44pKLgAAAAOIjY2VoZhaOHChXJ3d96TZTnvZw4AAOBAAgMDdeLECQ0dOtTsKKaj4AIAAGRwO3bs0KZNmzRv3jyzo9gFCi4AAEAGtnv3blWqVEmvv/663NzczI5jF1iDCwAAkEEtWbJEixcvlo+PD+X2Pyi4AAAAGVB0dLT++usvzZ07l3L7AJYoAAAAZDCLFi1Szpw5NWzYMLOj2CVmcAEAADKQr7/+Wnv37lXdunXNjmK3mMEFAADIIC5duqTKlSurZcuWcnVlnjIpFFwAAIAMYN68eTp8+LCmTZtmdhS7R8EFAACwc2fOnNHBgwcpt8nE3DYAAIAdW7hwoby8vDRjxgyWJSQTXyUAAAA7NXv2bP3666968sknzY6SobBEAQAAwA7FxMQob9686ty5s1xcXMyOk6FQcAEAAOzMjBkzFBkZqZ49e5odJUOi4AIAANiRtWvX6tSpU5o8ebLZUTIsCi4AAICd2LRpk2rXrq1GjRqxLOEx8CYzAAAAOzBlyhRt375dPj4+lNvHRMEFAAAwWXh4uCIjIzVhwgTKbSpgiQIAAICJJk6cqBdeeEF9+vQxO4rDYAYXAADAJFOnTlVwcLBef/11s6M4FGZwAQAATHDu3Dk1aNBAhQsXZllCKmMGFwAAIJ2NGzdOCxYsUJEiRSi3aYAZXAAAgHT0xx9/6O7duxoxYoTZURwWM7gAAADpZMqUKcqfP79GjhzJzG0aYgYXAAAgHYwcOVIxMTHKlSuX2VEcHgUXAAAgjUVGRuqFF15QvXr1zI7iFCi4AAAAaWjYsGEqWLCgOnToYHYUp8EaXAAAHiE4OFhXrlwxOwYyoIULF8rV1ZVym86YwQUA4CHOnz+vmjVr6urVq8qbN68qV65sdiRkAIZhaO3atWrRooU8PT3NjuN0mMEFACAJx44d06uvvqrTp0+rcOHC2rt3r7Jly2Z2LNg5wzA0ePBgnThxgnJrEmZwAQBIxP79+1WnTh3dvHlTpUqV0tatW1WgQAGzYyEDuH37tvLnz68uXbqYHcVpMYMLAMADtm/frjfffFM3b95UpUqV9P3331Nu8UiGYahfv346c+YM5dZkFFwAAP5jzZo1qlevnsLDw1WjRg1t375dTzzxhNmxkAEMHTpUOXPmVIUKFcyO4vRYogAAwP/MmzdPnTp1ksViUePGjbV06VJ5eXmZHQt2zjAM/fXXX+rUqRMz/XaCGVwAACSNHz9eH3zwgSwWizp06KCgoCDKLR7JMAz17t1bmzZtotzaEQouAMCp3V832bt3b0lS7969NXfuXLm5uZmcDBnBvn37VKBAAX366admR8F/UHABAE5t2bJlGjt2rCRp3LhxGjdunFxcXExOBXtnGIZGjhyp0qVLq3v37mbHwQMouAAAp3b06FFJUvv27a2zuMDDGIahHj16KFu2bMqaNavZcZAI3mQGAICk7Nmzmx0BGYBhGIqIiFDDhg315ptvmh0HSWAGFwAAIBkMw9Cnn36qzZs3U27tHAUXAAAgGaZOnapSpUqpcePGZkfBI7BEAQAA4CEsFouCgoLUrVs3zq6RQTCDCwAAkASLxaKuXbvq7t27lNsMhBlcAACARBiGoWvXrumVV15Rq1atzI4DGzCDCwAA8ACLxaKPPvpIt2/fptxmQBRcAIDTOnfunHbu3Gl2DNih7t27q2LFiipZsqTZUZACLFEAADid6OhoTZw4UcOHD9e9e/fk4eGhGjVqmB0LdsBisejEiRMaMGCA8ubNa3YcpBAzuAAAp/LDDz/oxRdfVL9+/XTv3j29/vrr+uOPP1S3bl2zo8FkcXFx6tixow4cOEC5zeAouAAApxASEqIOHTrotdde059//qlcuXJp0aJF2rlzJy9DQ5K0Y8cOvf7662rdurXZUfCYWKIAAHBohmFo4cKF+uyzz3Tjxg1JUseOHTV27FjlzJnT5HSwB3FxcRo4cKCGDBkib29vs+MgFVBwAQAO688//9RHH32kH374QZJUpkwZzZo1S6+88orJyWAv4uLi1KFDB9WqVYty60AouAAAhxMREaGRI0dq/Pjxio2Nla+vr4YOHaru3bvLw8PD7HiwE7Gxsbp37546deqkKlWqmB0HqYiCCwBwKBs3blTXrl11/vx5SVKDBg00bdo0FSpUyNxgsCuxsbFq37692rRpo5o1a5odB6mMggsASJTFYtGFCxdkGIbZURKIiYlRcHCwzp07Z52RDQ8P19ChQ7V69WpJkp+fn6ZNm6a3337bzKiwU+PGjVODBg0otw6KggsASFSTJk20du1as2PYzM3NTd27d9fQoUOVOXNms+PAzsTExGj58uXq16+fXF05mZSjouACABL122+/SZK8vb3l5uZmcpqE4uLiEuR66aWXNHnyZJUtW9akVLBnMTExatu2rRo3bky5dXAUXADAQ/3www+qUKGC2THiiYmJ0caNG1W3bl3eNIZkMQxDV65cUbNmzdSwYUOz4yCN8ecLAABwaNHR0WrRooUkUW6dBAUXAAA4tE6dOqlZs2Z66qmnzI6CdMISBQAA4JCio6N18uRJffHFF3riiSfMjoN0xAwuAABwOFFRUWrZsqX+/vtvyq0TYgYXAAA4nE2bNqldu3aqV6+e2VFgAgouAPxPXFycLl++bHYMuxEbG2t2BMBmUVFR6tu3r8aPHy93d2qOs2LkAUDS2bNnVa9ePZ04ccLsKABSKCoqSi1atNAHH3xAuXVyjD4Ap3fkyBHVrl1bV65ckZubG78Y/6NEiRIqVaqU2TGAR4qMjFRMTIwGDBigF1980ew4MBk/xQE4tX379qlu3bq6ffu2ypQpoy1btih//vxmxwJgg8jISDVv3lx9+vTRyy+/bHYc2AHOogDAaW3ZskU1atTQ7du3VaVKFe3Zs4dyC2RAI0aMUJcuXSi3sGIGF4BTWrFihVq1aqWYmBi99dZbWrVqlTJlymR2LAA2uHfvnoKCgjRy5Ei5uLiYHQd2hBlcAE5nzpw5atasmWJiYuTv769vvvmGcgtkMBEREWrWrJn8/Pwot0iAggvAaRiGoTFjxqhz584yDEMffvihli5dKk9PT7OjAbCBxWLR5cuX1b17d1WvXt3sOLBDFFwATsEwDH322Wfq37+/JGnAgAGaOXOm3NzcTE4GwBbh4eF69913lS1bNr3xxhtmx4GdYg0uAIcXGxurzp07a/78+ZKkiRMnqkePHianAmArwzDUpk0b9ejRQ7lz5zY7DuwYBReAw4qNjdWKFSs0btw4/fHHH3J1ddW8efPUrl07s6MBsFF4eLhOnz6t+fPnK1u2bGbHgZ0zfYnCjBkzVLhwYXl7e6tSpUrav3//Q/efPHmySpQoIR8fH/n5+alHjx6KjIxMp7QAMoLIyEjNmDFDxYsXV8uWLfXHH38oc+bMWr16NeUWyIDCwsLk7++v0NBQyi2SxdQZ3KCgIAUEBGj27NmqVKmSJk+erNq1a+vkyZPKkydPgv2XLVumvn37av78+apSpYpOnTqldu3aycXFRRMnTjThMwBgT0JCQjRlyhRNmTJFd+/elSTlzp1bn3zyibp06aKcOXOanBBASmzYsEF9+/bVq6++anYUZBCmFtyJEyeqY8eOat++vSRp9uzZ2rBhg+bPn6++ffsm2P+nn37SK6+8ohYtWkiSChcurObNm+uXX35J19wA7Mv58+c1ceJEffXVV7p3754kqWjRourVq5fatWsnHx8fkxMCSIm7d+9qzpw5Wrt2LWc7gU1MK7jR0dE6cOCA+vXrZ93m6uqqGjVqaN++fYkeU6VKFS1ZskT79+9XxYoVdfbsWW3cuFGtW7dO8nGioqIUFRVlvR0aGipJiomJUUxMjHX7/f//7zY4HsbZsfz+++/64osvtHLlSsXFxUmSypUrpxo1amjQoEHWYst4Ox6ey44vLCxMzZs315tvvqnY2FjOdeugknouP+5z27SCGxISori4OOXNmzfe9rx58+rEiROJHtOiRQuFhITo1VdflWEYio2N1Ycffmg97U9ixowZo2HDhiXYvnXrVvn6+ibYvm3bNhs/E2REjHPGZRiGjh49qjVr1ujQoUPW7WXLltW7776r559/Xi4uLtq1a5eJKZFeeC47poiICLm4uKhBgwby8/NjnJ3Ag2McERHxWPeXoc6isHv3bo0ePVozZ85UpUqVdPr0aX366acaMWKEBg0alOgx/fr1U0BAgPV2aGio/Pz8VKtWLWXNmtW6PSYmRtu2bVPNmjXl4eGR5p8LzME4Z1xxcXFat26dvvjiC/3222+S/n3Vp0mTJurZs6deeOEFSYyxs2CcHdedO3fUsmVLjR07Vg0bNmScHVxSz+X7r7inlGkFN1euXHJzc1NwcHC87cHBwcqXL1+ixwwaNEitW7fWBx98IEkqU6aMwsPD1alTJw0YMECurglPCuHl5SUvL68E2z08PBJ9siS1HY6Fcc44IiMjtXjxYk2YMEF//fWXJMnb21vvv/++evbsqaJFiyZ6HGPsHBhnxzNmzBgNHz5cL7zwgvVlasbZ8T04xo873qYVXE9PT5UvX147duxQo0aNJP176b0dO3aoW7duiR4TERGRoMTevwqRYRhpmheA7QzD0M2bN63rY20RFRWlJUuWaMqUKdY/hHPkyKFu3brp448/5iTvgIO5ffu21qxZowkTJrDeFo/N1CUKAQEBatu2rSpUqKCKFStq8uTJCg8Pt55VoU2bNipQoIDGjBkjSWrQoIEmTpyoF154wbpEYdCgQWrQoAGX2wTs0Mcff6wZM2Y89v34+fmpZ8+e6tChgzJnzpwKyQDYk9u3b8vf31+jRo2i3CJVmFpw/f39df36dQ0ePFhXr15VuXLltHnzZusbzy5cuBBvxnbgwIFycXHRwIEDdenSJeXOnVsNGjTQqFGjzPoUACThyJEjmjlz5mPdR9myZdWzZ081a9aMlycBBxUXF6fLly9r9OjRKl++vNlx4CBMf5NZt27dklySsHv37ni33d3dNWTIEA0ZMiQdkgF4HP369ZNhGHrvvfe0YsUKs+MAsEM3b95Uy5YtFRQUFO+N38DjMv1SvQAcz549e7Rhwwa5ubnxCguARFksFrVu3VqjR4+m3CLVmT6DC8CxGIahPn36SJI6deqkp59+2uREAOzNjRs3dPHiRa1YsUKZMmUyOw4cEDO4AFLV2rVr9csvv8jX11eDBw82Ow4AOxMSEqJmzZpJEuUWaYYZXACpJiYmxnr57Z49eyZ5TmsAzmvDhg364osv9Pzzz5sdBQ6Mggsg1cyfP1+nTp1S7ty51atXL7PjALAj169f1/DhwzV16lROBYY0R8EFnMT9iy6klaioKA0dOlTSv1cd5E0jAO67ceOGmjdvrsmTJ1NukS4ouICTaN68uYKCgtL8cYoUKaLOnTun+eMAyBhCQkLk7e2tL7/8UsWKFTM7DpwEbzIDnMSePXvS/DG8vb01ZcoUeXp6pvljAbB/wcHB8vf317Vr1yi3SFfM4AJO5uDBgypbtmya3LeLiwsvPwKwGjlypKZPn66iRYuaHQVOhoILOBlXV9d4l8AGgNR29epVbd68WdOmTTM7CpwUv+UAAECquXLlilq2bKnKlSubHQVOjIILAABSRWxsrK5du6aZM2eqRIkSZseBE6PgAgCAx3b58mXVq1dPJUqUoNzCdKzBBQAAjyUmJkbt2rXTjBkz5O3tbXYcgIILAABS7uLFi7p165a++eYb+fj4mB0HkMQSBQAAkEL//POP2rRpI19fX8ot7AozuAAAIEW2bt2qr776ivPcwu5QcAEAgE0uXLigCRMmaOrUqWZHARJFwQUAAMl26dIltWvXTvPmzTM7CpAkCi4AAEiWy5cvK2vWrFq8eLEKFixodhwgSbzJDAAAPNK5c+fUqlUrhYWFUW5h9yi4AADgkT7//HMtXLhQ+fPnNzsK8EgsUQAAAEk6e/as9u7dq1mzZpkdBUg2Ci5gJ+Li4nTv3r00u3+LxZJm9w3AMZ05c0YdO3bU4sWLzY4C2ISCC9iBO3fu6LnnntOlS5fMjgIAkqSoqCjdvn2bN5QhQ2INLmAHTpw4kS7ltmjRonr66afT/HEAZGx//fWX3n77bZUtW5ZyiwyJGVzAjhQqVEjHjx9Ps/v38vKSqyt/1wJIWkREhLp06aJFixbJ3Z2agIyJ71zAjri6unI9dwCmOXnypOLi4rRhwwZ5enqaHQdIMaZyAACATpw4oS5duihnzpyUW2R4FFwAAKDvv/9eS5cuVb58+cyOAjw2ligAAODEjh07pq+++koTJ040OwqQaii4AAA4qdOnT+vjjz/WsmXLzI4CpCoKLgAATuj8+fPKmzevAgMDlTt3brPjAKmKNbiAHbh48aLZEQA4kSNHjuiDDz5QTEwM5RYOiYILmGzz5s1q3bq1JKlKlSompwHg6AzD0PTp07V8+XLlzJnT7DhAmmCJAmCiwMBAtW7dWrGxsapTp47mzJljdiQADuyPP/7Qn3/+qS+//NLsKECaYgYXMMns2bPVokULxcbGqnnz5lq3bp18fX3NjgXAQf3+++/q2bOnatWqZXYUIM1RcIF0ZhiGRo0apY8++kiGYahLly5asmQJJ1YHkGbu3bunmJgYBQYG6oknnjA7DpDmKLhAOrJYLOrZs6cGDhwoSRo4cKCmT58uV1eeigDSxsGDB+Xv76/y5ctTbuE0WIMLpJPY2Fh17NhRCxculCRNmjRJ3bt3NzUTAMd2+/Zt9e/fX8uXL5eLi4vZcYB0Q8EF0kFkZKSaNWumb775Rm5ubpo/f77atGljdiwADuzAgQPKmjWr1q9fL3d3ft3DufAdDyRTXFycLBaLzceFhYWpcePG2rVrl7y8vLRixQo1bNgwDRICwL9+/fVXDRw4UEFBQZRbOCW+64Fk2LJli959911FRESk+D6yZMmib7/9Vq+//nrqBQOARBw8eFBBQUHKnj272VEAU1BwgWTYvXv3Y5VbPz8/rV27VuXLl0/FVAAQ3y+//KK1a9dq7NixZkcBTEXBBWzw0UcfafTo0TYflyVLFrm5uaVBIgD41x9//KEhQ4YoKCjI7CiA6Si4gA28vb15yQ+A3Tl58qQKFy6sFStWKGvWrGbHAUzHyTcBAMjAfvrpJ/Xo0UNubm6UW+B/KLgAAGRQFotFixcvVlBQkDJlymR2HMBusEQBAIAMaO/evQoODtbs2bPNjgLYHWZwAQDIYH744QeNHTtWtWvXNjsKYJeYwQUAIAMJCwuTj48PyxKAh2AGFwCADGL37t16//33Vb58ecot8BDM4AIAkAFcvXpVkyZN0vLly+Xi4mJ2HMCuMYMLAICd2717tyIjI7VmzRr5+vqaHQewexRcAADs2I4dOzRp0iTlzZuXKyICyUTBBQDAThmGoTNnzigwMFA+Pj5mxwEyDNbgAgBgh7Zu3aoff/xRw4YNMzsKkOFQcAEAsDM//vijZs2apeXLl5sdBciQWKIAAIAd+f3331WmTBktX75c3t7eZscBMiQKLgAAdmLjxo0aPny4vLy8KLfAY6DgAgBgB2JiYrRp0yYtW7ZMXl5eZscBMjTW4AIAYLL169fLxcVF06ZNMzsK4BCYwQUAwETfffedFi1apBo1apgdBXAYzOACAGCS27dvq0CBAlq6dKk8PT3NjgM4DGZwAQAwwbp16xQQEKAXX3yRcgukMmZwAQBIZ2fPnlVQUJAWL15sdhTAITGDCwBAOlq/fr28vb21bNkyeXh4mB0HcEgUXAAA0smqVau0fPly5c6dWy4uLmbHARwWSxQAAEgHhmHozp07WrRokdzd+fULpCWeYUAyxMXFmR0BQAYWFBSk8+fPq0+fPmZHAZwCBRd4hMjISAUFBUmSihUrZnIaABnN5s2btX79ei1YsMDsKIDToOACjzBz5kxduHBBBQsW1Pvvv292HAAZyP79+1WlShXVqFGDZQlAOuJNZsBD3L59W6NGjZIkDR8+XD4+PiYnApBRLFu2TDNnzlSmTJkot0A6o+ACDzFu3DjdvHlTzz33nNq0aWN2HAAZREREhA4dOqR58+bJzc3N7DiA0+FPSiAJly5d0uTJkyVJY8aM4ZcUgGT5+uuvVbBgQY0fP97sKIDTYgYXSMLQoUMVGRmpV199VfXr1zc7DoAM4Ouvv9aePXv02muvmR0FcGrM4AKJOH78uObPny/p32UKnJAdwKOEhITo+eefV8uWLeXqyvwRYCYKLpCI/v37y2KxqFGjRqpSpYrZcQDYufnz5+uPP/6wLmsCYC4KLvCAAwcOaN26dXJ1ddXo0aPNjgPAzh09elS//PKLZs2aZXYUAP/DayjAAw4dOiRJqlGjhp599lmT0wCwZ8uWLVPevHk1e/ZsliUAdoRnI5AEb29vsyMAsGNz5szR3r179cQTT7BOH7AzFFwAAGwUFxcnb29vTZ8+nZlbwA6xBhcAABvMnDlThmGoa9euZkcBkAT+7AQAIJmCgoJ04sQJdenSxewoAB6CGVwAAJLh+++/V926ddW0aVPW3AJ2jhlcAAAeYerUqVq7dq0yZ85MuQUyAAouAAAPcfv2bd26dUsTJ06k3AIZBEsU4NQOHjyoNm3a6O+//7Zui46ONjERAHsyefJkValSRUOGDDE7CgAbUHDhtPbs2aMGDRro7t27iX68fPny6ZwIgD2ZPHmyLl26pJdeesnsKABsRMGFU/ruu+/UokULRUVF6fXXX9fs2bPl4eFh/binp6cKFixoYkIAZrp69apq1qypUqVKsSwByIAouHA6u3bt0vTp0xUXF6eGDRsqKCiIq5YBsBo/frwiIiJYlgBkYLzJDE5l2rRpmjJliuLi4tS2bVutXr2acgvAat++fbp165YGDx5sdhQAj4GCC6dgGIYGDx6snj17SpI++eQTzZ8/X+7uvIgB4F9ffvmlSpUqpdGjR7MsAcjg+O0Oh2exWPTJJ59oxowZkqSWLVtq/PjxXD8egNXo0aN17949Zc2a1ewoAFIBBRcOLSYmRu3atdOyZcvk4uKiqVOnys/Pj9kZAFYxMTEqXry43nvvPX42AA6CgguHFRERoffee08bN26Uu7u7Fi9erCZNmmjjxo1mRwNgJ4YPH66iRYuqVatWZkcBkIoouHBIFotFDRs21I4dO+Tj46NVq1apbt26iomJMTsaADvx5ZdfShLlFnBAFFw4pJUrV2rHjh3KlCmTNm/erFdffdXsSADshGEY2rZtm1q3bi1fX1+z4wBIA7zLBg4nOjpaAwYMkCT17t2bcgvAyjAMDRkyRL/++ivlFnBgzODC4cydO1dnzpxRnjx5FBAQYHYcAHYkODhYOXLkUI8ePcyOAiANMYMLh3L37l0NHz5ckjRkyBBlzpzZ5EQA7IFhGBo0aJBu3rxJuQWcAAUXDmXixIm6du2aihcvro4dO5odB4CdGDx4sDJnzqxSpUqZHQVAOmCJAhxGcHCwJkyYIEkaNWqUPDw8TE4EwGyGYejixYtq06aNnn76abPjAEgnzODCYYwcOVJhYWGqUKGCmjRpYnYcACYzDEN9+vTRunXrKLeAk6HgwiGcOXNGs2fPliSNGzeOy/AC0LZt25QvXz59/PHHZkcBkM5oAXAIw4YNU2xsrN566y29+eabZscBYCLDMDRhwgRVrVqVM6kAToqCC4ewf/9+SdKnn35qchIAZjIMQz179pSnp6d8fHzMjgPAJLzJDA6FE7cDzsswDEVGRuqNN95QgwYNzI4DwETM4AIAMjzDMNS9e3ft2LGDcgvA/II7Y8YMFS5cWN7e3qpUqZL1peak3L59W127dlX+/Pnl5eWlZ555Rhs3bkyntAAAezR+/HiVKFFC9evXNzsKADtg6hKFoKAgBQQEaPbs2apUqZImT56s2rVr6+TJk8qTJ0+C/aOjo1WzZk3lyZNHq1atUoECBfT3338re/bs6R8eAGA6wzC0fv16ffrpp/Ly8jI7DgA7YWrBnThxojp27Kj27dtLkmbPnq0NGzZo/vz56tu3b4L958+fr5s3b+qnn36ynsS/cOHC6RkZAGAnLBaLPv30U73wwguUWwDxmFZwo6OjdeDAAfXr18+6zdXVVTVq1NC+ffsSPebbb79V5cqV1bVrV33zzTfKnTu3WrRooT59+sjNzS3RY6KiohQVFWW9HRoaKkmKiYlRTEyMdfv9///vNmQchmFIkmJjYx86hoyz42OMnUNMTIyuX7+usmXLqn379oy3g+L57PiSGuPHHfPHKriRkZHy9vZO0bEhISGKi4tT3rx5423PmzevTpw4kegxZ8+e1c6dO9WyZUtt3LhRp0+fVpcuXRQTE6MhQ4YkesyYMWM0bNiwBNu3bt2a6Dvut23bloLPBmYLDw+XJP3888+6e/fuI/dnnB0fY+y4LBaLvvrqKzVq1Ej58+fnfRhOgOez43twjCMiIh7r/mwuuBaLRaNGjdLs2bMVHBysU6dOqWjRoho0aJAKFy6sDh06PFagRz12njx5NGfOHLm5ual8+fK6dOmSxo8fn2TB7devX7wTfYeGhsrPz0+1atVS1qxZrdtjYmK0bds21axZ07r8ARlHpkyZJEkvv/yyqlatmuR+jLPjY4wd3yeffKL69esrT548jLOD4/ns+JIa4/uvuKeUzQV35MiRWrRokT7//HN17NjRur106dKaPHlysgturly55ObmpuDg4Hjbg4ODlS9fvkSPyZ8/vzw8POItR3j22Wd19epVRUdHy9PTM8ExXl5eia7N8vDwSPTJktR22DcXFxdJkru7e7LGj3F2fIyx47FYLLpw4YL69u2rJ598Uhs3bmScnQTj7PgeHOPHHW+bTxO2ePFizZkzRy1btoxXNMuWLZvk0oLEeHp6qnz58tqxY4d1m8Vi0Y4dO1S5cuVEj3nllVd0+vRpWSwW67ZTp04pf/78iZZbAIBjiIuLU6dOnbR3714VKlTI7DgA7JzNBffSpUsqXrx4gu0Wi8XmBcEBAQGaO3euFi1apOPHj+ujjz5SeHi49awKbdq0ifcmtI8++kg3b97Up59+qlOnTmnDhg0aPXq0unbtauunAQDIQL755htVrVpVrVq1MjsKgAzA5iUKpUqV0g8//JDgL+hVq1bphRdesOm+/P39df36dQ0ePFhXr15VuXLltHnzZusbzy5cuCBX1//v4H5+ftqyZYt69Oih559/XgUKFNCnn36qPn362PppAAAygLi4OI0ePVr9+vWTuztXlweQPDb/tBg8eLDatm2rS5cuyWKxaM2aNTp58qQWL16s9evX2xygW7du6tatW6If2717d4JtlStX1s8//2zz4wAAMpa4uDh98MEHql69OuUWgE1sXqLw9ttv67vvvtP27duVKVMmDR48WMePH9d3332nmjVrpkVGAICTiYuLU2RkpFq1asWyBAA2S9GfxFWrVuWcdACANBEbG6sOHTqoQ4cOql69utlxAGRANs/gFi1aVDdu3Eiw/fbt2ypatGiqhAIAOK9hw4apbt26eu2118yOAiCDsnkG9/z584qLi0uwPSoqSpcuXUqVUHBOhw4dUvPmzZN1JbIHPXg+ZQAZT2xsrL777jsNHjyYc54CeCzJLrjffvut9f+3bNmibNmyWW/HxcVpx44dKly4cKqGg/MwDEMff/yxTp48meL78PT05FUEIIOKiYlRu3bt9M4771BuATy2ZBfcRo0aSfr3ilFt27aN9zEPDw8VLlxYX3zxRaqGg/P47rvv9OOPP8rHx0dbtmxRlixZbL6PAgUKKHfu3GmQDkBaO3v2rJo0aaJ33nnH7CgAHECyC+79q4cVKVJEv/76q3LlypVmoeBcYmNjrRf06N69u6pWrWpyIgDpJSYmRh988IHGjx9PuQWQamxeg3vu3Lm0yAEntnjxYh07dkw5c+ZU7969zY4DIJ0YhqH27durcePGypMnj9lxADiQFJ0mLDw8XHv27NGFCxcUHR0d72OffPJJqgSDc4iIiNDgwYMlSQMGDFD27NnNDQQgXURHR+vixYsaN26cChQoYHYcAA7G5oJ76NAh1a1bVxEREQoPD1fOnDkVEhIiX19f5cmTh4ILm0ybNk2XLl3SU089pS5dupgdB0A6iI6OVqtWrdSmTRvVr1/f7DgAHJDN58Ht0aOHGjRooFu3bsnHx0c///yz/v77b5UvX14TJkxIi4xwUDdv3tSYMWMkSSNGjJC3t7fJiQCkhxUrVqh169aUWwBpxuaCe/jwYfXs2VOurq5yc3NTVFSU/Pz89Pnnn6t///5pkREOasyYMbpz546ef/55tWzZ0uw4ANJYVFSUBg4cqBYtWqhBgwZmxwHgwGxeouDh4SFX1397cZ48eXThwgU9++yzypYtm/75559UD4iUi46OVv369XXixAmzoyTq8uXLkqSxY8fKzc3N5DQA0lJUVJRatmyp999/3/o7BADSis0F94UXXtCvv/6qp59+WtWqVdPgwYMVEhKir7/+WqVLl06LjEihP//8U9u2bTM7xkPVqlVLb731ltkxAKShqKgoRUdHKyAgQFWqVDE7DgAnYHPBHT16tPVSqqNGjVKbNm300Ucf6emnn9a8efNSPSBSzjAMSf/OtG/YsMHkNAm5urqqVKlScnFxMTsKgDQSGRmpFi1aaODAgZRbAOnG5oJboUIF6//nyZNHmzdvTtVASH2enp7xxg0A0ku/fv3UuXNnvfjii2ZHAeBEUm0h1MGDB3lHLABAknTv3j2tWrVKEyZMUO3atc2OA8DJ2FRwt2zZol69eql///46e/asJOnEiRNq1KiRXnrpJevlfAEAzuvevXtq1qyZsmfPzhtIAZgi2UsU5s2bp44dOypnzpy6deuWvvrqK02cOFEff/yx/P39dfToUT377LNpmRUAYOcMw9CpU6f0ySefqHr16mbHAeCkkj2DO2XKFI0bN04hISFasWKFQkJCNHPmTB05ckSzZ8+m3AKAk4uIiFDTpk1VuHBhyi0AUyW74J45c0bvvfeeJOndd9+Vu7u7xo8fr4IFC6ZZOABAxmCxWNSiRQt17dpV2bJlMzsOACeX7CUK9+7dk6+vryTJxcVFXl5eyp8/f5oFAwBkDOHh4bp69armzJmjPHnymB0HAGw7TdhXX32lzJkzS5JiY2O1cOFC5cqVK94+n3zySeqlAwDYtbCwMDVr1kx9+vRR1apVzY4DAJJsKLhPPfWU5s6da72dL18+ff311/H2cXFxoeACgBMJDAyk3AKwO8kuuOfPn0/DGACAjOTu3bsaPXq0Ro8ezdUIAdidVLvQAwDAOdy9e1f+/v6qX78+5RaAXbL5Ur0AAOcVFhYmwzA0evRolStXzuw4AJAoZnABAMkSGhqq9957T1euXKHcArBrFFwAQLL07t1bQ4cOVYkSJcyOAgAPxRIFAMBD3blzR1u3btXMmTPl6sq8CAD7l6KfVGfOnNHAgQPVvHlzXbt2TZK0adMm/fnnn6kaDgBgrtu3b8vf31+FCxem3ALIMGz+abVnzx6VKVNGv/zyi9asWaOwsDBJ0u+//64hQ4akekAAgDkMw9CpU6c0cuRIvfTSS2bHAYBks7ng9u3bVyNHjtS2bdvk6elp3f7mm2/q559/TtVwAABz3Lp1S40aNVKZMmVUoUIFs+MAgE1sLrhHjhzRO++8k2B7njx5FBISkiqhAADmiYmJUfPmzTVkyBD5+PiYHQcAbGbzm8yyZ8+uK1euqEiRIvG2Hzp0SAUKFEi1YACA9Hfz5k3dunVLy5YtU86cOc2OAwApYvMMbrNmzdSnTx9dvXpVLi4uslgs+vHHH9WrVy+1adMmLTICANLBjRs35O/vr7t371JuAWRoNhfc0aNHq2TJkvLz81NYWJhKlSql1157TVWqVNHAgQPTIiMAIB0EBgZqwoQJXMQBQIZn8xIFT09PzZ07V4MGDdLRo0cVFhamF154QU8//XRa5AMApLGQkBB98cUXGjNmjNlRACBV2Fxw9+7dq1dffVVPPfWUnnrqqbTIBABIJyEhIWrevLkmTpxodhQASDU2F9w333xTBQoUUPPmzdWqVSuVKlUqLXIhBbp27aqdO3dab9+7d8/ENADs3e3bt+Xh4aFp06apZMmSZscBgFRj8xrcy5cvq2fPntqzZ49Kly6tcuXKafz48bp48WJa5EMyhYaGaubMmTpx4oT1399//y1JKlq0qMnpANiba9euqXHjxrpz5w7lFoDDsXkGN1euXOrWrZu6deumc+fOadmyZVq0aJH69eun1157Ld4MItKPYRjW/9++fbs8PDwkSS4uLipfvrxZsQDYqT59+mjatGksNQPgkGwuuP9VpEgR9e3bV2XLltWgQYO0Z8+e1MqFx1C1atV4V5kDgPuCg4P1ww8/aP78+XJxcTE7DgCkCZuXKNz3448/qkuXLsqfP79atGih0qVLa8OGDamZDQCQiq5evWr9eU25BeDIbJ7B7devnwIDA3X58mXVrFlTU6ZM0dtvvy1fX9+0yAcASAUWi0WnT5/WjBkzWHMLwOHZXHC///57ffbZZ2ratKly5cqVFpkAAKno8uXL6ty5s9asWWNdnw8Ajszmgvvjjz+mRQ4AQBq4d++eWrdurVmzZlFuATiNZBXcb7/9VnXq1JGHh4e+/fbbh+7bsGHDVAkGAHg8ly5dUnR0tNauXausWbOaHQcA0k2yCm6jRo109epV5cmTR40aNUpyPxcXF8XFxaVWNgBACl28eFFt2rTRnDlzKLcAnE6yCq7FYkn0/wEA9mnVqlWaO3euihUrZnYUAEh3Np8mbPHixYqKikqwPTo6WosXL06VUACAlLlw4YIGDBig7t27U24BOC2bC2779u11586dBNvv3r2r9u3bp0ooAIDt/vnnH7Vr104dOnQwOwoAmMrmsygYhpHoCcIvXryobNmypUooAIBtrl+/rixZsmjBggUqVKiQ2XEAwFTJLrgvvPCCXFxc5OLiourVq8vd/f8PjYuL07lz5/TWW2+lSUgAQNLOnz+v9u3ba8WKFZRbAJANBff+2RMOHz6s2rVrK3PmzNaPeXp6qnDhwmrcuHGqBwQAJM0wDA0aNEgLFy5U7ty5zY4DAHYh2QV3yJAhkqTChQvL399f3t7eaRYKAPBo586d0+HDh7V48eJEl44BgLOy+U1mbdu2pdwCgMnOnj2rDh06qEKFCpRbAHhAsmZwc+bMqVOnTilXrlzKkSPHQ3+Y3rx5M9XCIWlDhw7VunXrrLe5wAbgPOLi4vTPP/9o8eLFKliwoNlxAMDuJKvgTpo0SVmyZLH+P7MF5vr55581bNiwRD/25JNPxnsDIADHcvr0afXs2VNr166Vq6vNL8IBgFNIVhNq27at9f/btWuXVlmQDIZhqE+fPpKkJk2aqFOnTvE+XrZsWX7pAQ7qzp076ty5sxYvXszzHAAewuapvoMHD8rDw0NlypSRJH3zzTdasGCBSpUqpaFDh8rT0zPVQ+L/bdq0Sd9//728vLw0ceJE+fn5mR0JQDr466+/5OXlpW+//VaZMmUyOw4A2DWbpwA6d+6sU6dOSfr3TQ7+/v7y9fXVypUr1bt371QPiP8XFxdnnb395JNPKLeAkzh58qQ+/PBDeXh4UG4BIBlsLrinTp1SuXLlJEkrV65UtWrVtGzZMi1cuFCrV69O7Xz4jyVLlujo0aPKnj27+vbta3YcAOlk/fr1WrJkifLnz292FADIEFJ0qV6LxSJJ2r59u+rXry9J8vPzU0hISOqmg1VkZKQGDRokSerXr59y5sxpciIAae348eMKDAxM8k2lAIDE2VxwK1SooJEjR6pGjRras2ePZs2aJenfE47nzZs31QPiXzNmzNA///yjAgUK6OOPPzY7DoA0dvLkSXXr1k3Lli0zOwoAZDg2L1GYPHmyDh48qG7dumnAgAEqXry4JGnVqlWqUqVKqgeEdPv2bY0aNUqSNHz4cPn4+JicCEBaunz5snLnzq1ly5YxcQAAKWDzDO7zzz+vI0eOJNg+fvx4ubm5pUooxDd+/HjdunVLpUqVUps2bcyOAyANHT16VN27d9eaNWtYigQAKZTiKwIcOHBAx48flySVKlVKL774YqqFQnw7duyQJPXu3ZuLOAAOzGKxaOzYsVq+fLmyZs1qdhwAyLBsbkvXrl2Tv7+/9uzZo+zZs0v69yX0N954Q4GBgcqdO3dqZ3R6hmFIErM5gAM7cuSIzp8/ryVLlpgdBQAyPJvX4H788ccKCwvTn3/+qZs3b+rmzZs6evSoQkND9cknn6RFRgBwaH/88YcCAgJUuXJls6MAgEOweQZ38+bN2r59u5599lnrtlKlSmnGjBmqVatWqoYDAEcXExOjGzduKDAwUE888YTZcQDAIdg8g2uxWOTh4ZFgu4eHh/X8uACARzt06JCaN2+u119/nXILAKnI5oL75ptv6tNPP9Xly5et2y5duqQePXqoevXqqRoOABzVtWvX1KdPH82ZM0cuLi5mxwEAh2JzwZ0+fbpCQ0NVuHBhFStWTMWKFVORIkUUGhqqadOmpUVGAHAohw8fVmxsrL799lvePAoAacDmNbh+fn46ePCgduzYYT1N2LPPPqsaNWqkejgAcDQHDhxQ//79FRQUJG9vb7PjAIBDsqngBgUF6dtvv1V0dLSqV6/OJWMBwEa7du1SUFCQ9TSLAIDUl+yCO2vWLHXt2lVPP/20fHx8tGbNGp05c0bjx49Py3xOzzAMXbp0SZKUJUsWk9MASKn9+/dr69atGjhwoNlRAMDhJXsN7vTp0zVkyBCdPHlShw8f1qJFizRz5sy0zAZJJ06c0KVLl+Tl5aVKlSqZHQdAChw8eFCDBw/mVS8ASCfJLrhnz55V27ZtrbdbtGih2NhYXblyJU2C4V/btm2TJL366qvy8fExOQ0AW50/f15PPfWUgoKClC1bNrPjAIBTSHbBjYqKUqZMmf7/QFdXeXp66t69e2kSDP+6X3Br1qxpchIAttq3b58++ugjZcqUiXILAOnIpjeZDRo0SL6+vtbb0dHRGjVqVLwf3BMnTky9dE4uJiZGu3fvlkTBBTKamJgYzZo1SytWrODVFwBIZ8kuuK+99ppOnjwZb1uVKlV09uxZ621OVp66fv75Z4WFhSlXrlwqV66c2XEAJNOPP/6osLAwLV682OwoAOCUkl1w788kIv1s3bpVklSjRg25utp8TQ4AJti7d6/GjBmjwMBAs6MAgNOy+UIPSD+svwUylqioKMXExCgoKEiZM2c2Ow4AOC2mBe3UrVu39Ouvv0qi4AIZwffff68OHTrojTfeoNwCgMmYwbVTu3btksViUYkSJeTn52d2HAAPcf78eY0fP55lCQBgJ5jBtVMsTwAyhr1798rX11erV6+OdypFAIB5KLh2ioIL2L+dO3dq/Pjxypw5szw9Pc2OAwD4nxQV3B9++EGtWrVS5cqVdenSJUnS119/rb1796ZqOGd17tw5nTlzRm5ubnr99dfNjgMgCYcPH1ZgYGC884MDAMxnc8FdvXq1ateuLR8fHx06dEhRUVGSpDt37mj06NGpHtAZ3Z+9ffnll5U1a1aT0wB40Pbt2zV+/HgFBARwEQcAsEM2F9yRI0dq9uzZmjt3rjw8PKzbX3nlFR08eDBVwzkrlicA9mvPnj2aPn26unXrZnYUAEASbD6LwsmTJ/Xaa68l2J4tWzbdvn07NTI5tbi4OO3YsUMSBRewN3/99ZdKlSqlwMBAeXt7mx0HAJAEm2dw8+XLp9OnTyfYvnfvXhUtWjRVQjmzgwcP6tatW8qaNasqVqxodhwA/7N582b16dNH2bNnp9wCgJ2zueB27NhRn376qX755Re5uLjo8uXLWrp0qXr16qWPPvooLTI6lfvLE9544w25u3OaYsAe3Lt3T6tWrdKyZcviLc0CANgnmxtU3759ZbFYVL16dUVEROi1116Tl5eXevXqpY8//jgtMjqVY8eOSZIqV65schIAkrRx40ZlypRJX331ldlRAADJZHPBdXFx0YABA/TZZ5/p9OnTCgsLU6lSpbg0ZSoxDEOS5OXlZXISAOvXr9eiRYu0ZMkSs6MAAGyQ4tfAPT09VapUqdTMAgB2IyIiQlmyZNHSpUu5iAMAZDA2F9w33nhDLi4uSX58586djxUIAMz2zTffaNOmTZo9e7bZUQAAKWBzwS1Xrly82zExMTp8+LCOHj2qtm3bplYuADDFsWPHtHz5ci1evNjsKACAFLK54E6aNCnR7UOHDlVYWNhjBwIAs2zZskUVKlTQkiVLOIsJAGRgNp8mLCmtWrXS/PnzU+vuACBdrVmzRosWLVLWrFkptwCQwaVawd23bx8nPweQIRmGoQsXLmjRokWc5xYAHIDN0xTvvvtuvNuGYejKlSv67bffNGjQoFQLBgDpYcWKFbp27Zq6d+9udhQAQCqxueBmy5Yt3m1XV1eVKFFCw4cPV61atVItGACkte+++07fffedFixYYHYUAEAqsqngxsXFqX379ipTpoxy5MiRVpkAIM0dPXpUlStXVp06dVhzCwAOxqY1uG5ubqpVq5Zu376dRnEAIO0tW7ZMEyZMUM6cOSm3AOCAbH6TWenSpXX27Nm0yAIAae7OnTvat2+f5s2bJ1fXVHufLQDAjtj8033kyJHq1auX1q9frytXrig0NDTePwCwV0uXLtWpU6c0bdo0ubm5mR0HAJBGkl1whw8frvDwcNWtW1e///67GjZsqIIFCypHjhzKkSOHsmfPzrpcAHbr66+/1o4dO/Tiiy+aHQUAkMaSvfhs2LBh+vDDD7Vr1660zAMAqe7u3bsqWrSoWrRowcwtADiBZBdcwzAkSdWqVUv1EDNmzND48eN19epVlS1bVtOmTVPFihUfeVxgYKCaN2+ut99+W+vWrUv1XAAyvoULF+rYsWP6/PPPzY4CAEgnNq3BdXFxSfUAQUFBCggI0JAhQ3Tw4EGVLVtWtWvX1rVr1x563Pnz59WrVy9VrVo11TMBcAz79+/XTz/9pLFjx5odBQCQjmwquM8884xy5sz50H+2mjhxojp27Kj27durVKlSmj17tnx9fTV//vwkj4mLi1PLli01bNgwFS1a1ObHBOD41qxZo5IlS2r27NmcLQEAnIxNJ4AcNmxYgiuZPY7o6GgdOHBA/fr1s25zdXVVjRo1tG/fviSPGz58uPLkyaMOHTrohx9+eOhjREVFKSoqynr7/pkeYmJiFBMTY91+////u80MFotF0r8l3uwsjshexhlpJyYmRlu3blV0dLQaNWqkuLg4xcXFmR0LqYznsnNgnB1fUmP8uGNuU8Ft1qyZ8uTJ81gP+F8hISGKi4tT3rx5423PmzevTpw4kegxe/fu1bx583T48OFkPcaYMWM0bNiwBNu3bt0qX1/fBNu3bduWrPtNK5cvX5YkHTt2TBs3bjQ1iyMze5yRdiwWi2JjY1W3bl1t3rzZ7DhIYzyXnQPj7PgeHOOIiIjHur9kF9y0WH9rq7t376p169aaO3eucuXKlaxj+vXrp4CAAOvt0NBQ+fn5qVatWsqaNat1e0xMjLZt26aaNWvKw8Mj1bMnV2BgoCSpVKlSqlu3rmk5HJW9jDPSxpw5c+Tu7q66desyxg6O57JzYJwdX1Jj/LjXVrD5LAqpKVeuXHJzc1NwcHC87cHBwcqXL1+C/c+cOaPz58+rQYMG1m33X9J3d3fXyZMnVaxYsXjHeHl5ycvLK8F9eXh4JPpkSWp7erm/VtDNzY0ncxoye5yR+pYsWaITJ07oiy++0KZNmxhjJ8E4OwfG2fE9OMaPO97JfueFxWJJ1eUJkuTp6any5ctrx44d8R5nx44dqly5coL9S5YsqSNHjujw4cPWfw0bNtQbb7yhw4cPy8/PL1XzAcgYDh06pLp162rq1Kl28WoTAMBcNq3BTQsBAQFq27atKlSooIoVK2ry5MkKDw9X+/btJUlt2rRRgQIFNGbMGHl7e6t06dLxjs+ePbskJdgOwDlMnz5dp0+f1qRJkyi3AABJdlBw/f39df36dQ0ePFhXr15VuXLltHnzZusbzy5cuMApfgAk6tq1a7p8+TLlFgAQj+kFV5K6deumbt26Jfqx3bt3P/TYhQsXpn6gNHDr1i316NEjwXrjByX37BCAs5s2bZrefPNNjR492uwoAAA7YxcF1xls2rRJixYtSvb+ib3JDsC/Jk+erIsXL6pUqVJmRwEA2CEKbjq5f8LiMmXKqFevXg/d94knnlDt2rXTIxaQ4dy+fVuVK1dWxYoVWZYAAEgUBTedFSxYUG3atDE7BpAhTZgwQVFRURowYIDZUQAAdoyCCyBD2LFjh0JCQjRmzBizowAA7BwFF4DdW7Rokd577z29+eabLEsAADwSBReAXRszZozCw8Pl4+NDuQUAJAsFF4Ddio6OVr58+dSuXTvKLQAg2Si4AOzSiBEjVKpUKetVDQEASC4uEQbA7kybNk1xcXFq3Lix2VEAABkQM7gA7Mq+ffvUunVrZc+e3ewoAIAMioILwC4YhqGhQ4fKw8NDlStXNjsOACADo+ACsAsXLlxQpkyZ1Lt3b7OjAAAyONbgAjCVYRgaNmyYLBYL5RYAkCoouABMNWjQIHl5ealIkSJmRwEAOAiWKAAwhWEYunHjhpo0aaJy5cqZHQcA4ECYwQWQ7gzDUN++fbVy5UrKLQAg1VFwAaS7devWKU+ePProo4/MjgIAcEAsUQCQbgzD0KxZs9SxY0d5eHiYHQcA4KCYwQWQLgzDUK9evRQdHU25BQCkKWZwAaQ5wzB07949VapUSU2bNjU7DgDAwTGDCyBNGYahHj166KeffqLcAgDSBQUXQJoaOXKknn76adWoUcPsKAAAJ8ESBQBpwjAMff/99+rRo4cyZ85sdhwAgBNhBhdAqrNYLPr44491/Phxyi0AIN0xgwsg1Z08eVJly5ZVx44dzY4CAHBCzOACSDUWi0UBAQHKkSMH5RYAYBoKLoBUYRiGunXrplKlSilfvnxmxwEAODGWKAB4bBaLRdevX7cWXAAAzMQMLoDHYrFY9OGHH2rnzp2UWwCAXaDgAngsS5YsUZUqVdS8eXOzowAAIIklCgBSKC4uTpMnT1aPHj3k6srfygAA+8FvJQA2i4uLU8eOHZU3b17KLQDA7jCDC8AmcXFxioiIUOPGjVWvXj2z4wAAkABTLwCSLS4uTh06dNCxY8cotwAAu0XBBZBsffv2Ve3atVWpUiWzowAAkCSWKAB4pNjYWO3evVvDhw+Xj4+P2XEAAHgoZnABPFRsbKzat2+vW7duUW4BABkCBRfAQ/3xxx9q2LCh3nvvPbOjAACQLBRcAImKiYlRx44dVbRoUcotACBDoeACSMBisaht27aqU6eOsmfPbnYcAABswpvMAMQTHR2tGzduaPjw4SpevLjZcQAAsBkzuACsoqOj1bp1ax0+fJhyCwDIsCi4AKzmz5+vli1bqk6dOmZHAQAgxViiAEBRUVGaOHGi+vbtKxcXF7PjAADwWJjBBZxcVFSUWrVqpTJlylBuAQAOgRlcwIlFR0fr3r176tq1q15//XWz4wAAkCqYwQWcVGRkpJo3b65Lly5RbgEADoWCCzipHj16qGPHjnruuefMjgIAQKpiiQLgZCIjI7Vnzx5NmTJFnp6eZscBACDVMYMLOJF79+6pWbNmcnV1pdwCABwWM7iAEzl48KC6deumGjVqmB0FAIA0wwwu4AQiIiLUunVrvfDCC5RbAIDDo+ACDi42NlbNmzfX+++/L19fX7PjAACQ5liiADiw8PBwhYaGatq0aXrqqafMjgMAQLpgBjed3LhxQ5Lk5eVlchI4i/DwcPn7++vs2bOUWwCAU6HgppMdO3ZIkl555RWTk8BZzJkzR5999hnfcwAAp8MShXQQHR2tPXv2SJJq1qxpcho4urCwME2dOlX9+/c3OwoAAKZgBjcd7Nu3T+Hh4cqTJ4/KlCljdhw4sLCwMPn7++u1114zOwoAAKZhBjcdbNu2TZJUo0YNubryNwXSxr179xQVFaUhQ4aoYsWKZscBAMA0tK10cL/gsjwBaSU0NFTvvvuuQkNDKbcAAKdHwU1jt27d0m+//SaJgou08/HHH2vw4MEqUqSI2VEAADAdSxTS2M6dO2WxWPTss8+qQIECZseBg7lz54727dunefPmyd2dpzMAABIzuGmO5QlIK3fu3JG/v79y5sxJuQUA4D8ouGls69atkii4SH0HDhzQ8OHDWXMLAMADmPZJQ2fOnNG5c+fk7u6uatWqmR0HDuLWrVv68MMPtWTJEnl4eJgdBwAAu8MMbhq6vzyhcuXKypIli8lp4AgiIyPVrFkz9e7dm3ILAEASmMFNQ6y/RWq6efOmoqOjtXDhQuXPn9/sOAAA2C1mcNNIXFycdu7cKUmqVauWyWmQ0d28eVP+/v4KDg6m3AIA8AgU3DTy22+/6fbt28qePbsqVKhgdhxkcHPnztX48eNVtmxZs6MAAGD3WKKQRu4vT3jzzTfl5uZmchpkVCEhIfryyy81YMAAs6MAAJBhMIObRlh/i8cVEhKi5s2bq0GDBmZHAQAgQ2EGNw2EhYVp3759kii4SJmwsDBZLBZNnjxZzz33nNlxAADIUJjBTQNHjhxRTEyMnnzySRUrVszsOMhgrl27prffflsWi4VyCwBAClBw00BcXJwkKXPmzCYnQUZjGIY+/vhjTZ06Vfny5TM7DgAAGRJLFAA7ERwcrMOHD2vZsmW8MREAgMfADC5gB65evaoWLVroqaeeotwCAPCYKLiAyQzD0OHDhzV9+nQ9++yzZscBACDDo+ACJrpy5Yr8/f1Vq1Ytyi0AAKmENbiASUJDQ9WqVSvNmjVLrq78rQkAQGqh4AImuHz5sjw8PBQYGKjcuXObHQcAAIfCtBGQzi5duqRWrVrpzp07lFsAANIABRdIZwsWLNCcOXNUvHhxs6MAAOCQWKIApJOLFy9qyZIlGjhwoNlRAABwaMzgAungn3/+UZs2bdS0aVOzowAA4PCYwQXS2J07d+Tu7q558+apSJEiZscBAMDhMYMLpKG///5b77zzjnx8fCi3AACkEwoukEYMw1BAQIDmz5+v7Nmzmx0HAACnwRIFIA2cO3dOp0+f1sqVK7mIAwAA6YzfvEAqO3v2rDp06KASJUpQbgEAMAEzuEAqMgxDx44d06JFi+Tn52d2HAAAnBLTS0AqOX36tJo1a6Z69epRbgEAMBEzuEAquH79ujp16qTFixfLxcXF7DgAADg1ZnCBx3TmzBm5urpq9erVKliwoNlxAABwehRc4DGcOnVKnTp1UlRUlHLkyGF2HAAAIJYoAI9l+fLlWrJkifLnz292FAAA8D8UXCAFTpw4oe+++05DhgwxOwoAAHgABRew0YkTJ9S1a1ctXbrU7CgAACARFFzABjdu3FDmzJm1bNky5c2b1+w4AAAgEbzJDEimP//8U02bNlXOnDkptwAA2DEKLpAMsbGxGjRokJYvXy5fX1+z4wAAgIdgiQLwCEeOHFFISIhWr17NRRwAAMgAmMEFHuKPP/5Qjx49VLp0acotAAAZBDO4QBIsFov+/vtvBQYGKleuXGbHAQAAycQMLpCI33//XW3btlWDBg0otwAAZDDM4AIPuHDhgj777DMtX77c7CgAACAFmMEF/uPIkSPKkiWL1qxZoyeeeMLsOAAAIAUouMD/HDhwQD179pRhGMqcObPZcQAAQAqxRAH4n++++05BQUHKkSOH2VEAAMBjoOCmgWPHjkmSvL29TU6C5Pjtt9+0d+9eDR061OwoAAAgFVBwU9m9e/c0fPhwSVK7du3MDYNH+u233zRw4EAFBgaaHQUAAKQSu1iDO2PGDBUuXFje3t6qVKmS9u/fn+S+c+fOVdWqVZUjRw7lyJFDNWrUeOj+6W3q1Km6dOmSChUqpC5dupgdBw8RHBysvHnzKigoSNmzZzc7DgAASCWmF9ygoCAFBARoyJAhOnjwoMqWLavatWvr2rVrie6/e/duNW/eXLt27dK+ffvk5+enWrVq6dKlS+mcPKGbN29qzJgxkqQRI0bIy8vL5ERIyi+//KJ27dopX758ypYtm9lxAABAKjK94E6cOFEdO3ZU+/btVapUKc2ePVu+vr6aP39+ovsvXbpUXbp0Ubly5VSyZEl99dVXslgs2rFjRzonT2jMmDG6c+eOnn/+ebVo0cLsOEhCdHS0Jk2apKCgIHl4eJgdBwAApDJT1+BGR0frwIED6tevn3Wbq6uratSooX379iXrPiIiIhQTE6OcOXMm+vGoqChFRUVZb4eGhkqSYmJiFBMTY91+////u80WFy5c0LRp0yRJI0eOlMVikcViSdF9Ie388MMPOnPmjBYvXixPT88Ujzfs1+M+l5ExMM7OgXF2fEmN8eOOuakFNyQkRHFxccqbN2+87Xnz5tWJEyeSdR99+vTRk08+qRo1aiT68TFjxmjYsGEJtm/dulW+vr4Jtm/bti1Zj/ugqVOnKioqSqVLl1ZcXJw2btyYovtB2jl+/LhWrVqlXr16afv27WbHQRpL6XMZGQvj7BwYZ8f34BhHREQ81v1l6LMojB07VoGBgdq9e3eSp+Tq16+fAgICrLdDQ0Ot63azZs1q3R4TE6Nt27apZs2aNr9sfeTIEe3atUuS9OWXX+qll15KwWeDtBQbG2v9w2Pfvn0pGmdkDI/zXEbGwTg7B8bZ8SU1xvdfcU8pUwturly55ObmpuDg4Hjbg4ODlS9fvoceO2HCBI0dO1bbt2/X888/n+R+Xl5eib7Zy8PDI9EnS1LbH2bIkCEyDENNmjRRlSpVbDoWae/777/X119/rblz51pf8kjJOCNjYYydA+PsHBhnx/fgGD/ueJv6JjNPT0+VL18+3hvE7r9hrHLlykke9/nnn2vEiBHavHmzKlSokB5Rk/T9999r/fr1cnNz06hRo0zNgoROnjypzz//XJMnTzY7CgAASCemL1EICAhQ27ZtVaFCBVWsWFGTJ09WeHi42rdvL0lq06aNChQoYD391rhx4zR48GAtW7ZMhQsX1tWrVyVJmTNnVubMmdM1u2EY6tOnjySpY8eOeuaZZ9L18fFwv/zyi0qUKKGVK1fKx8fH7DgAACCdmF5w/f39df36dQ0ePFhXr15VuXLltHnzZusbzy5cuCBX1/+faJ41a5aio6PVpEmTePczZMiQdL/U6rp16/Tzzz/L19dXQ4YMSdfHxsPt2rVLkyZNUmBgIOUWAAAnY3rBlaRu3bqpW7duiX5s9+7d8W6fP38+7QMlQ2xsrPX0Zj179nzkmmGkH8MwtGfPHgUGBiZ6pgwAAODY7KLgZkTz58/XyZMnlStXLvXq1cvsOPifHTt26NSpU+k+mw8AAOwHBTcFwsPDrQVq0KBB8U43BvPs2rVL06ZN0/Lly82OAgAATGT6pXozoilTpujKlSsqUqSIOnfubHYcSLp48aKKFSum5cuXs+YWAAAnR8G1UUhIiMaNGyfp30vyJnaOXaSvLVu26NNPP1XBggUptwAAgIJrq9GjRys0NFTlypVTs2bNzI7j9EJDQ7VkyRItXbo03tk2AACA82INrg3Onz+vGTNmSPr3fLwUKnNt2rRJefLk0ddff212FAAAYEdoaDYYPHiwoqOjVb16ddWsWdPsOE5tw4YNmjdvnkqXLm12FAAAYGcouMn0+++/a8mSJZKksWPHysXFxeREzis6OlqGYWjp0qWsgQYAAAmwRCGZ+vbtK8Mw5O/vrwoVKpgdx2l9++232rFjh6ZMmWJ2FAAAYKcouMmwc+dObd68We7u7ho1apTZcZzWwYMHtXTpUtbcAgCAh2KJwiMYhqE+ffpIkj788EMVK1bM5ETOadeuXSpevLiWLFkiT09Ps+MAAAA7RsF9hFWrVum3335T5syZNWjQILPjOKW1a9dqzpw58vHxkYeHh9lxAACAnaPgPkRMTIz69+8vSerVq5fy5MljciLnYxiG/vzzTy1evJhyCwAAkoU1uA/x1Vdf6fTp08qTJ48CAgLMjuN0Vq9erbCwMA0cONDsKAAAIANhBvchFixYIEnq37+/smTJYnIa57Ju3TqtXbtWLVu2NDsKAADIYJjBfYh79+5JEhcTSGfnzp1T+fLlVb9+fbm78y0KAABswwwu7EpgYKCGDRumggULUm4BAECKUHBhN65fv65du3bpq6++4kpxAAAgxSi4sAvLly/X9evX9eWXXzJzCwAAHgsFF6ZbsmSJtm3bphIlSpgdBQAAOAAKLkwVGRmpXLlyae7cuXJzczM7DgAAcAC8FgzTLFq0SH/99ZdGjhxpdhQAAOBAKLgwxZ49e7R37159+eWXZkcBAAAOhoKLdLdhwwZVq1ZNVatWlasrq2QAAEDqol0gXc2bN0/fffedfH19KbcAACBN0DCQbmJjY3Xjxg3NnDmTcgsAANIMSxSQLubMmaMcOXKod+/eZkcBAAAOjmk0pLmFCxfq999/V+PGjc2OAgAAnAAzuEhTJ0+eVK1atdS2bVsuvwsAANIFM7hIMzNmzNCsWbP05JNPUm4BAEC6oeAiTVy4cEHnzp3TpEmTzI4CAACcDAUXqW7WrFmKjY3VhAkTmLkFAADpjoKLVDVlyhSdPn1aRYoUMTsKAABwUrzJDKkmPDxcpUuX1ieffMLMLQAAMA0FF6niiy++UFxcHOe5BQAApmOJAh7bd999p2vXrumzzz4zOwoAAAAzuHg8K1euVIMGDVS/fn2WJQAAALvADC5SbNy4cTp06JC8vLwotwAAwG4wg4sUiYyMVObMmdW7d2/KLQAAsCsUXNhs1KhRKl++vLp27Wp2FAAAgARYogCbTJo0SdHR0apdu7bZUQAAABLFDC6S7ejRo2rZsqXy5MljdhQAAIAkMYOLZBk2bJjWrl1LuQUAAHaPGVw80okTJ+Tu7q4BAwaYHQUAAOCRmMFFkgzD0JgxY5QtWzbKLQAAyDAouEiUYRgaPHiwDMNQ/vz5zY4DAACQbCxRQAKGYeju3buqXbu2Xn31VbPjAAAA2ISCi3gMw1D//v1VtGhRdezY0ew4AAAANmOJAuJZunSpcubMSbkFAAAZFjO4kPTvzO2iRYvUqlUrubvzbQEAADIuZnAhwzDUu3dv3bp1i3ILAAAyPNqMkzMMQ2FhYSpdurTatm1rdhwAAIDHxgyuEzMMQwEBATpy5AjlFgAAOAwKrhMbPHiwihYtqipVqpgdBQAAINWwRMEJGYahgwcPqnv37nriiSfMjgMAAJCqmMF1MoZh6NNPP9X+/fsptwAAwCExg+tkDh48qFKlSunDDz80OwoAAECaYAbXSVgsFvXt21dFixal3AIAAIdGwXUChmGoW7duKlasmHLkyGF2HAAAgDTFEgUHZ7FYFBoaqvbt2+ull14yOw4AAECaYwbXgVksFn300Ufatm0b5RYAADgNCq4D+/LLL/Xyyy/rvffeMzsKAABAumGJggOKi4vT3Llz9eGHH8rFxcXsOAAAAOmKGVwHExcXp06dOsnHx4dyCwAAnBIzuA7EYrHozp07qlevnt59912z4wAAAJiCGVwHERcXpw4dOujixYuUWwAA4NQouA6iR48eqlmzpp5//nmzowAAAJiKJQoZXGxsrA4cOKARI0YoW7ZsZscBAAAwHTO4GVhsbKzat2+v8+fPU24BAAD+hxncDOynn35SgwYN1LRpU7OjAAAA2A0KbgYUGxurgIAAjRkzRpkyZTI7DgAAgF1hiUIGExsbq7Zt26patWqUWwAAgEQwg5uBxMTEKCwsTH369OFsCQAAAElgBjeDiI6OVuvWrfXrr79SbgEAAB6CgptBTJ06Vc2aNVOtWrXMjgIAAGDXWKJg56KjozV37lz17NlTLi4uZscBAACwexTc/wkJCdG2bdt04cIFubm5SZJu3Lhhaqbo6Gi1atVKrVu3ptwCAAAkEwX3fwYOHKj58+cn+jEvL690TiPFxcXp1q1b+uCDD1iWAAAAYAMK7v+EhIRIkl544QUVK1bMur1w4cJ6+eWX0zVLVFSUWrZsqXHjxlFuAQAAbETBfUDHjh310UcfmZrhww8/VIcOHeIVbQAAACQPBdeOREZG6uDBg5o+fToXcQAAAEghThNmJyIjI9W8eXOFhYVRbgEAAB4DBddO7NmzRx999BFrbgEAAB4TSxRMdu/ePX366aeaPn26PD09zY4DAACQ4TGDa6KoqCg1a9ZM/v7+lFsAAIBUwgyuSSIiIhQVFaVx48apZMmSZscBAABwGMzgmiA8PFz+/v46ceIE5RYAACCVUXBNMGnSJPXq1UuVK1c2OwoAAIDDYYlCOgoLC9P8+fM1cOBAs6MAAAA4LGZw00lYWJiaNWumF1980ewoAAAADo0Z3HQQExOj27dva8CAASxLAAAASGPM4Kaxu3fv6u2335abmxvlFgAAIB1QcNNYhw4dNHDgQOXPn9/sKAAAAE6BJQppJDQ0VEeOHNHixYvl7e1tdhwAAACnwQxuGrhz546aNm0qd3d3yi0AAEA6o+Cmgd27d2vYsGGqVKmS2VEAAACcDksUUtHt27cVEBCguXPnys3Nzew4AAAATokZ3FQSFhYmf39/denShXILAABgImZwU8GtW7fk4uKi2bNnq0iRImbHAQAAcGrM4D6mmzdvyt/fXxcvXqTcAgAA2AEK7mOaNGmSxo0bp9KlS5sdBQAAAGKJQorduHFDy5Yt04gRI8yOAgAAgP9gBjcFQkJC1KxZM7322mtmRwEAAMADmMG1UVRUlMLCwvTFF1/o+eefNzsOAAAAHsAMrg2uX7+u+vXrK1u2bJRbAAAAO0XBTSbDMPTBBx9o0qRJypEjh9lxAAAAkASWKCTDtWvX9Ndff2nlypXy9PQ0Ow4AAAAeghncRwgODlaLFi2UI0cOyi0AAEAGQMF9hB9++EFTp05VqVKlzI4CAACAZGCJQhKuXr2qfv36af78+XJxcTE7DgAAAJLJLmZwZ8yYocKFC8vb21uVKlXS/v37H7r/ypUrVbJkSXl7e6tMmTLauHFjqua5efOmWrZsqb59+1JuAQAAMhjTC25QUJACAgI0ZMgQHTx4UGXLllXt2rV17dq1RPf/6aef1Lx5c3Xo0EGHDh1So0aN1KhRIx09ejRV8ty5c0dubm5avHixSpQokSr3CQAAgPRjesGdOHGiOnbsqPbt26tUqVKaPXu2fH19NX/+/ET3nzJlit566y199tlnevbZZzVixAi9+OKLmj59eqrkWbBggW7cuKECBQqkyv0BAAAgfZm6Bjc6OloHDhxQv379rNtcXV1Vo0YN7du3L9Fj9u3bp4CAgHjbateurXXr1iW6f1RUlKKioqy3Q0NDJUkxMTGKiYmxbjcMQ5Lk7+8vPz+/eB+D47g/royv42KMnQPj7BwYZ8eX1Bg/7pibWnBDQkIUFxenvHnzxtueN29enThxItFjrl69muj+V69eTXT/MWPGaNiwYQm2b926Vb6+vtbbvr6+Klu2rAzDSPU1vbA/27ZtMzsC0hhj7BwYZ+fAODu+B8c4IiLise7P4c+i0K9fv3gzvqGhofLz81OtWrWUNWtW6/aaNWtq27Ztqlmzpjw8PMyIinQQExPDODs4xtg5MM7OgXF2fEmN8f1X3FPK1IKbK1cuubm5KTg4ON724OBg5cuXL9Fj8uXLZ9P+Xl5e8vLySrDdw8Mj0SdLUtvhWBhnx8cYOwfG2Tkwzo7vwTF+3PE29U1mnp6eKl++vHbs2GHdZrFYtGPHDlWuXDnRYypXrhxvf+nfae2k9gcAAIBzMX2JQkBAgNq2basKFSqoYsWKmjx5ssLDw9W+fXtJUps2bVSgQAGNGTNGkvTpp5+qWrVq+uKLL1SvXj0FBgbqt99+05w5c8z8NAAAAGAnTC+4/v7+un79ugYPHqyrV6+qXLly2rx5s/WNZBcuXJCr6/9PNFepUkXLli3TwIED1b9/fz399NNat26dSpcunazHu3+2hAfXdsTExCgiIkKhoaG8DOLAGGfHxxg7B8bZOTDOji+pMb7f0+73Nlu5GCk9MoO6ePGi/Pz8zI4BAACAR/jnn39UsGBBm49zuoJrsVh0+fJlZcmSJd5leO+fXeGff/6Jd3YFOBbG2fExxs6BcXYOjLPjS2qMDcPQ3bt39eSTT8Z7JT+5TF+ikN5cXV0f+pdA1qxZeRI5AcbZ8THGzoFxdg6Ms+NLbIyzZcuW4vsz/VK9AAAAQGqi4AIAAMChUHD/x8vLS0OGDEn0ohBwHIyz42OMnQPj7BwYZ8eXVmPsdG8yAwAAgGNjBhcAAAAOhYILAAAAh0LBBQAAgEOh4AIAAMChOFXBnTFjhgoXLixvb29VqlRJ+/fvf+j+K1euVMmSJeXt7a0yZcpo48aN6ZQUj8OWcZ47d66qVq2qHDlyKEeOHKpRo8Yjvy9gPlufy/cFBgbKxcVFjRo1StuASBW2jvPt27fVtWtX5c+fX15eXnrmmWf4uZ0B2DrOkydPVokSJeTj4yM/Pz/16NFDkZGR6ZQWtvr+++/VoEEDPfnkk3JxcdG6deseeczu3bv14osvysvLS8WLF9fChQttf2DDSQQGBhqenp7G/PnzjT///NPo2LGjkT17diM4ODjR/X/88UfDzc3N+Pzzz41jx44ZAwcONDw8PIwjR46kc3LYwtZxbtGihTFjxgzj0KFDxvHjx4127doZ2bJlMy5evJjOyZFcto7xfefOnTMKFChgVK1a1Xj77bfTJyxSzNZxjoqKMipUqGDUrVvX2Lt3r3Hu3Dlj9+7dxuHDh9M5OWxh6zgvXbrU8PLyMpYuXWqcO3fO2LJli5E/f36jR48e6ZwcybVx40ZjwIABxpo1awxJxtq1ax+6/9mzZw1fX18jICDAOHbsmDFt2jTDzc3N2Lx5s02P6zQFt2LFikbXrl2tt+Pi4ownn3zSGDNmTKL7N23a1KhXr168bZUqVTI6d+6cpjnxeGwd5wfFxsYaWbJkMRYtWpRWEfGYUjLGsbGxRpUqVYyvvvrKaNu2LQU3A7B1nGfNmmUULVrUiI6OTq+ISAW2jnPXrl2NN998M962gIAA45VXXknTnEgdySm4vXv3Np577rl42/z9/Y3atWvb9FhOsUQhOjpaBw4cUI0aNazbXF1dVaNGDe3bty/RY/bt2xdvf0mqXbt2kvvDfCkZ5wdFREQoJiZGOXPmTKuYeAwpHePhw4crT5486tChQ3rExGNKyTh/++23qly5srp27aq8efOqdOnSGj16tOLi4tIrNmyUknGuUqWKDhw4YF3GcPbsWW3cuFF169ZNl8xIe6nVv9xTM5S9CgkJUVxcnPLmzRtve968eXXixIlEj7l69Wqi+1+9ejXNcuLxpGScH9SnTx89+eSTCZ5csA8pGeO9e/dq3rx5Onz4cDokRGpIyTifPXtWO3fuVMuWLbVx40adPn1aXbp0UUxMjIYMGZIesWGjlIxzixYtFBISoldffVWGYSg2NlYffvih+vfvnx6RkQ6S6l+hoaG6d++efHx8knU/TjGDCyTH2LFjFRgYqLVr18rb29vsOEgFd+/eVevWrTV37lzlypXL7DhIQxaLRXny5NGcOXNUvnx5+fv7a8CAAZo9e7bZ0ZCKdu/erdGjR2vmzJk6ePCg1qxZow0bNmjEiBFmR4OdcYoZ3Fy5csnNzU3BwcHxtgcHBytfvnyJHpMvXz6b9of5UjLO902YMEFjx47V9u3b9fzzz6dlTDwGW8f4zJkzOn/+vBo0aGDdZrFYJEnu7u46efKkihUrlrahYbOUPJfz588vDw8Pubm5Wbc9++yzunr1qqKjo+Xp6ZmmmWG7lIzzoEGD1Lp1a33wwQeSpDJlyig8PFydOnXSgAED5OrKvF1Gl1T/ypo1a7JnbyUnmcH19PRU+fLltWPHDus2i8WiHTt2qHLlyokeU7ly5Xj7S9K2bduS3B/mS8k4S9Lnn3+uESNGaPPmzapQoUJ6REUK2TrGJUuW1JEjR3T48GHrv4YNG+qNN97Q4cOH5efnl57xkUwpeS6/8sorOn36tPUPGEk6deqU8ufPT7m1UykZ54iIiAQl9v4fNf++hwkZXar1L9ve/5ZxBQYGGl5eXsbChQuNY8eOGZ06dTKyZ89uXL161TAMw2jdurXRt29f6/4//vij4e7ubkyYMME4fvy4MWTIEE4TlgHYOs5jx441PD09jVWrVhlXrlyx/rt7965ZnwIewdYxfhBnUcgYbB3nCxcuGFmyZDG6detmnDx50li/fr2RJ08eY+TIkWZ9CkgGW8d5yJAhRpYsWYzly5cbZ8+eNbZu3WoUK1bMaNq0qVmfAh7h7t27xqFDh4xDhw4ZkoyJEycahw4dMv7++2/DMAyjb9++RuvWra373z9N2GeffWYcP37cmDFjBqcJe5Rp06YZTz31lOHp6WlUrFjR+Pnnn60fq1atmtG2bdt4+69YscJ45plnDE9PT+O5554zNmzYkM6JkRK2jHOhQoUMSQn+DRkyJP2DI9lsfS7/FwU347B1nH/66SejUqVKhpeXl1G0aFFj1KhRRmxsbDqnhq1sGeeYmBhj6NChRrFixQxvb2/Dz8/P6NKli3Hr1q30D45k2bVrV6K/Z++Pa9u2bY1q1aolOKZcuXKGp6enUbRoUWPBggU2P66LYTCnDwAAAMfhFGtwAQAA4DwouAAAAHAoFFwAAAA4FAouAAAAHAoFFwAAAA6FggsAAACHQsEFAACAQ6HgAgAAwKFQcAFA0sKFC5U9e3azY6SYi4uL1q1b99B92rVrp0aNGqVLHgAwEwUXgMNo167d/7V3/zFR138Ax58cBneeh43SwQX+KOXmStMTKjVXksWxrJuoUN6mE1In4TnNyjVDroZmBQ5aP2hOMGKBtBosEooVdVxboQVsoocYlE1WCzYYxQXcvb9/OG+dAma6r+18Pbb74/P+8fq83h/+efG+9wcICQm55NPR0XG9U6OkpMSfj0ajISYmhg0bNvDbb79dk/jd3d0kJycD0NXVRUhICM3NzQFjCgoKKCkpuSb3G0tOTo5/naGhocTGxrJp0yZ6e3uvKI4U40KIqzHheicghBDXksViobi4OKBtypQp1ymbQBEREbjdbnw+Hy0tLWzYsIFz585RV1d31bGjoqIuO2by5MlXfZ9/4s4776S+vh6v18vJkydJT0+nr6+PioqK/8v9hRBCdnCFEEElPDycqKiogE9oaCj5+fnMnTsXvV5PbGwsmZmZDAwMjBmnpaWFZcuWYTAYiIiIYOHChRw7dszf39jYyNKlS9HpdMTGxmK32/njjz/GzS0kJISoqCiMRiPJycnY7Xbq6+sZHBzE5/Px0ksvERMTQ3h4OPPnz6e2ttY/d2hoiKysLKKjo9FqtUyfPp19+/YFxL5wRGHmzJkALFiwgJCQEB588EEgcFf03XffxWg04vP5AnK0Wq2kp6f7r6uqqjCbzWi1Wm6//XYcDgcjIyPjrnPChAlERUVx2223sXz5ctasWcPnn3/u7/d6vWRkZDBz5kx0Oh0mk4mCggJ/f05ODocPH6aqqsq/G9zQ0ADA2bNnSU1N5eabbyYyMhKr1UpXV9e4+QghbjxS4AohbggajYbCwkJOnDjB4cOH+eKLL3juuefGHG+z2YiJiaGpqYnjx4+za9cubrrpJgDOnDmDxWJh1apVtLa2UlFRQWNjI1lZWVeUk06nw+fzMTIyQkFBAXl5ebz++uu0traSlJTE448/zunTpwEoLCykurqaI0eO4Ha7KSsrY8aMGaPG/e677wCor6+nu7ubjz766JIxa9asoaenhy+//NLf1tvbS21tLTabDQCn08m6devYtm0bbW1tFBUVUVJSQm5u7j9eY1dXF3V1dYSFhfnbfD4fMTExVFZW0tbWRnZ2Ni+88AJHjhwBYOfOnaSmpmKxWOju7qa7u5vFixczPDxMUlISBoMBp9OJy+Vi0qRJWCwWhoaG/nFOQogbgBJCiCCxfv16FRoaqvR6vf+zevXqUcdWVlaqW265xX9dXFysJk+e7L82GAyqpKRk1LkZGRlq06ZNAW1Op1NpNBo1ODg46pyL47e3t6u4uDgVHx+vlFLKaDSq3NzcgDkJCQkqMzNTKaXU1q1bVWJiovL5fKPGB9THH3+slFKqs7NTAeqHH34IGLN+/XpltVr911arVaWnp/uvi4qKlNFoVF6vVyml1EMPPaT27t0bEKO0tFRFR0ePmoNSSu3Zs0dpNBql1+uVVqtVgAJUfn7+mHOUUurpp59Wq1atGjPXC/c2mUwBz+Cvv/5SOp1O1dXVjRtfCHFjkTO4QoigsmzZMt5++23/tV6vB87vZu7bt49Tp07R39/PyMgIHo+HP//8k4kTJ14SZ8eOHTz11FOUlpb6v2a/4447gPPHF1pbWykrK/OPV0rh8/no7Oxkzpw5o+bW19fHpEmT8Pl8eDwe7r//fg4ePEh/fz/nzp1jyZIlAeOXLFlCS0sLcP54wcMPP4zJZMJisbBixQoeeeSRq3pWNpuNjRs38tZbbxEeHk5ZWRlPPPEEGo3Gv06XyxWwY+v1esd9bgAmk4nq6mo8Hg/vv/8+zc3NbN26NWDMm2++yaFDh/j5558ZHBxkaGiI+fPnj5tvS0sLHR0dGAyGgHaPx8OZM2f+xRMQQgQrKXCFEEFFr9cza9asgLauri5WrFjBli1byM3NJTIyksbGRjIyMhgaGhq1UMvJyWHt2rXU1NRw9OhR9uzZQ3l5OStXrmRgYIDNmzdjt9svmTdt2rQxczMYDHz//fdoNBqio6PR6XQA9Pf3X3ZdZrOZzs5Ojh49Sn19PampqSxfvpwPP/zwsnPH8thjj6GUoqamhoSEBJxOJwcOHPD3DwwM4HA4SElJuWSuVqsdM25YWJj/Z/DKK6/w6KOP4nA4ePnllwEoLy9n586d5OXlsWjRIgwGA6+99hrffvvtuPkODAywcOHCgF8sLvivvEgohPhvkAJXCBH0jh8/js/nIy8vz787eeG853ji4uKIi4tj+/btPPnkkxQXF7Ny5UrMZjNtbW2XFNKXo9FoRp0TERGB0WjE5XLxwAMP+NtdLhf33HNPwLi0tDTS0tJYvXo1FouF3t5eIiMjA+JdOO/q9XrHzUer1ZKSkkJZWRkdHR2YTCbMZrO/32w243a7r3idF9u9ezeJiYls2bLFv87FixeTmZnpH3PxDmxYWNgl+ZvNZioqKpg6dSoRERFXlZMQIrjJS2ZCiKA3a9YshoeHeeONN/jxxx8pLS3lnXfeGXP84OAgWVlZNDQ08NNPP+FyuWhqavIfPXj++ef55ptvyMrKorm5mdOnT1NVVXXFL5n93bPPPsv+/fupqKjA7Xaza9cumpub2bZtGwD5+fl88MEHnDp1ivb2diorK4mKihr1n1NMnToVnU5HbW0tv/76K319fWPe12azUVNTw6FDh/wvl12QnZ3Ne++9h8Ph4MSJE5w8eZLy8nJ27959RWtbtGgR8+bNY+/evQDMnj2bY8eOUVdXR3t7Oy+++CJNTU0Bc2bMmEFraytut5vff/+d4eFhbDYbt956K1arFafTSWdnJw0NDdjtdn755ZcrykkIEdykwBVCBL27776b/Px89u/fz1133UVZWVnAn9i6WGhoKD09Paxbt464uDhSU1NJTk7G4XAAMG/ePL766iva29tZunQpCxYsIDs7G6PR+K9ztNvt7Nixg2eeeYa5c+dSW1tLdXU1s2fPBs4fb3j11VeJj48nISGBrq4uPv30U/+O9N9NmDCBwsJCioqKMBqNWK3WMe+bmJhIZGQkbrebtWvXBvQlJSXxySef8Nlnn5GQkMB9993HgQMHmD59+hWvb/v27Rw8eJCzZ8+yefNmUlJSSEtL495776WnpydgNxdg48aNmEwm4uPjmTJlCi6Xi4kTJ/L1118zbdo0UlJSmDNnDhkZGXg8HtnRFUIECFFKqeudhBBCCCGEENeK7OAKIYQQQoigIgWuEEIIIYQIKlLgCiGEEEKIoCIFrhBCCCGECCpS4AohhBBCiKAiBa4QQgghhAgqUuAKIYQQQoigIgWuEEIIIYQIKlLgCiGEEEKIoCIFrhBCCCGECCpS4AohhBBCiKDyP0fOGVvl7z6xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 8 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 8 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "import os, random, numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 81 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.7638 - accuracy: 0.4583 - val_loss: 0.7457 - val_accuracy: 0.4479\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.4705 - val_loss: 0.7402 - val_accuracy: 0.4583\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7521 - accuracy: 0.4792 - val_loss: 0.7349 - val_accuracy: 0.4792\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7466 - accuracy: 0.4948 - val_loss: 0.7299 - val_accuracy: 0.4896\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7412 - accuracy: 0.5017 - val_loss: 0.7251 - val_accuracy: 0.4948\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7361 - accuracy: 0.5226 - val_loss: 0.7204 - val_accuracy: 0.5156\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7311 - accuracy: 0.5295 - val_loss: 0.7160 - val_accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7263 - accuracy: 0.5434 - val_loss: 0.7117 - val_accuracy: 0.5365\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.5556 - val_loss: 0.7075 - val_accuracy: 0.5365\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.5608 - val_loss: 0.7035 - val_accuracy: 0.5365\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7129 - accuracy: 0.5712 - val_loss: 0.6996 - val_accuracy: 0.5365\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.5851 - val_loss: 0.6959 - val_accuracy: 0.5365\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.5903 - val_loss: 0.6923 - val_accuracy: 0.5469\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7006 - accuracy: 0.6042 - val_loss: 0.6888 - val_accuracy: 0.5521\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.6076 - val_loss: 0.6854 - val_accuracy: 0.5573\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6198 - val_loss: 0.6821 - val_accuracy: 0.5729\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6895 - accuracy: 0.6198 - val_loss: 0.6790 - val_accuracy: 0.5781\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.6215 - val_loss: 0.6760 - val_accuracy: 0.5833\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.6337 - val_loss: 0.6730 - val_accuracy: 0.5781\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6441 - val_loss: 0.6702 - val_accuracy: 0.5938\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.6528 - val_loss: 0.6674 - val_accuracy: 0.6146\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.6510 - val_loss: 0.6647 - val_accuracy: 0.6198\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.6562 - val_loss: 0.6621 - val_accuracy: 0.6302\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6670 - accuracy: 0.6562 - val_loss: 0.6596 - val_accuracy: 0.6302\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6597 - val_loss: 0.6572 - val_accuracy: 0.6354\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.6615 - val_loss: 0.6548 - val_accuracy: 0.6354\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6586 - accuracy: 0.6615 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6632 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.6667 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.6719 - val_loss: 0.6459 - val_accuracy: 0.6510\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6736 - val_loss: 0.6439 - val_accuracy: 0.6562\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6753 - val_loss: 0.6418 - val_accuracy: 0.6615\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6753 - val_loss: 0.6398 - val_accuracy: 0.6771\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.6753 - val_loss: 0.6379 - val_accuracy: 0.6771\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6806 - val_loss: 0.6360 - val_accuracy: 0.6823\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6788 - val_loss: 0.6342 - val_accuracy: 0.6875\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.6788 - val_loss: 0.6324 - val_accuracy: 0.6979\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6840 - val_loss: 0.6307 - val_accuracy: 0.6979\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6823 - val_loss: 0.6290 - val_accuracy: 0.6979\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6823 - val_loss: 0.6273 - val_accuracy: 0.7031\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6262 - accuracy: 0.6840 - val_loss: 0.6257 - val_accuracy: 0.6927\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6840 - val_loss: 0.6241 - val_accuracy: 0.6875\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.6823 - val_loss: 0.6225 - val_accuracy: 0.6875\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6806 - val_loss: 0.6210 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6185 - accuracy: 0.6858 - val_loss: 0.6195 - val_accuracy: 0.6875\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6840 - val_loss: 0.6181 - val_accuracy: 0.6771\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.6892 - val_loss: 0.6166 - val_accuracy: 0.6823\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6910 - val_loss: 0.6153 - val_accuracy: 0.6823\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.6927 - val_loss: 0.6139 - val_accuracy: 0.6927\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6962 - val_loss: 0.6126 - val_accuracy: 0.6875\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6962 - val_loss: 0.6113 - val_accuracy: 0.6875\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.6979 - val_loss: 0.6100 - val_accuracy: 0.6875\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6979 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6944 - val_loss: 0.6075 - val_accuracy: 0.6875\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6962 - val_loss: 0.6063 - val_accuracy: 0.6927\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6962 - val_loss: 0.6052 - val_accuracy: 0.6979\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6979 - val_loss: 0.6040 - val_accuracy: 0.6979\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.6962 - val_loss: 0.6029 - val_accuracy: 0.6979\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.6962 - val_loss: 0.6018 - val_accuracy: 0.6979\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5945 - accuracy: 0.6962 - val_loss: 0.6007 - val_accuracy: 0.6979\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5931 - accuracy: 0.6997 - val_loss: 0.5996 - val_accuracy: 0.6927\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.7014 - val_loss: 0.5986 - val_accuracy: 0.6927\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7014 - val_loss: 0.5976 - val_accuracy: 0.6927\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.6997 - val_loss: 0.5966 - val_accuracy: 0.6927\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.7014 - val_loss: 0.5956 - val_accuracy: 0.6927\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.7014 - val_loss: 0.5946 - val_accuracy: 0.6979\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.6997 - val_loss: 0.5937 - val_accuracy: 0.7031\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.7014 - val_loss: 0.5927 - val_accuracy: 0.7031\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.7031 - val_loss: 0.5918 - val_accuracy: 0.7031\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.7031 - val_loss: 0.5909 - val_accuracy: 0.6979\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.7049 - val_loss: 0.5900 - val_accuracy: 0.6979\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7031 - val_loss: 0.5891 - val_accuracy: 0.6979\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.7049 - val_loss: 0.5883 - val_accuracy: 0.6979\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7066 - val_loss: 0.5874 - val_accuracy: 0.6979\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5753 - accuracy: 0.7083 - val_loss: 0.5866 - val_accuracy: 0.6979\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.7101 - val_loss: 0.5858 - val_accuracy: 0.6979\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5731 - accuracy: 0.7118 - val_loss: 0.5850 - val_accuracy: 0.6979\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.7118 - val_loss: 0.5842 - val_accuracy: 0.6979\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5708 - accuracy: 0.7118 - val_loss: 0.5834 - val_accuracy: 0.7031\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5698 - accuracy: 0.7135 - val_loss: 0.5827 - val_accuracy: 0.7031\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.7135 - val_loss: 0.5819 - val_accuracy: 0.7031\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7118 - val_loss: 0.5812 - val_accuracy: 0.7031\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.7118 - val_loss: 0.5804 - val_accuracy: 0.7083\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5656 - accuracy: 0.7170 - val_loss: 0.5797 - val_accuracy: 0.7083\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.7153 - val_loss: 0.5790 - val_accuracy: 0.7083\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5636 - accuracy: 0.7170 - val_loss: 0.5783 - val_accuracy: 0.7083\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5626 - accuracy: 0.7170 - val_loss: 0.5776 - val_accuracy: 0.7135\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7170 - val_loss: 0.5769 - val_accuracy: 0.7135\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7170 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7222 - val_loss: 0.5756 - val_accuracy: 0.7188\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7188 - val_loss: 0.5750 - val_accuracy: 0.7188\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5579 - accuracy: 0.7205 - val_loss: 0.5743 - val_accuracy: 0.7188\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5570 - accuracy: 0.7222 - val_loss: 0.5737 - val_accuracy: 0.7188\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5561 - accuracy: 0.7222 - val_loss: 0.5731 - val_accuracy: 0.7188\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.7205 - val_loss: 0.5725 - val_accuracy: 0.7188\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7222 - val_loss: 0.5718 - val_accuracy: 0.7188\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7222 - val_loss: 0.5712 - val_accuracy: 0.7188\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7240 - val_loss: 0.5707 - val_accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7240 - val_loss: 0.5701 - val_accuracy: 0.7188\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7188 - val_loss: 0.5695 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=100, batch_size=32)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.498032  ],\n",
       "       [0.47510898],\n",
       "       [0.5763236 ],\n",
       "       [0.31110892],\n",
       "       [0.3703766 ],\n",
       "       [0.61320966],\n",
       "       [0.42372942],\n",
       "       [0.25438112],\n",
       "       [0.20729397],\n",
       "       [0.848382  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.719, roc-auc is 0.745\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}, roc-auc is {:.3f}'.format(\n",
    "    accuracy_score(y_test, y_pred_class_nn_1), roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19bfcf87be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 400 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.7222 - val_loss: 0.5689 - val_accuracy: 0.7135\n",
      "Epoch 2/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5492 - accuracy: 0.7240 - val_loss: 0.5683 - val_accuracy: 0.7188\n",
      "Epoch 3/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.7240 - val_loss: 0.5678 - val_accuracy: 0.7188\n",
      "Epoch 4/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5476 - accuracy: 0.7222 - val_loss: 0.5672 - val_accuracy: 0.7135\n",
      "Epoch 5/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5467 - accuracy: 0.7257 - val_loss: 0.5667 - val_accuracy: 0.7135\n",
      "Epoch 6/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7240 - val_loss: 0.5661 - val_accuracy: 0.7135\n",
      "Epoch 7/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5451 - accuracy: 0.7240 - val_loss: 0.5656 - val_accuracy: 0.7135\n",
      "Epoch 8/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5444 - accuracy: 0.7240 - val_loss: 0.5650 - val_accuracy: 0.7135\n",
      "Epoch 9/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5436 - accuracy: 0.7257 - val_loss: 0.5645 - val_accuracy: 0.7135\n",
      "Epoch 10/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.7257 - val_loss: 0.5640 - val_accuracy: 0.7135\n",
      "Epoch 11/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7240 - val_loss: 0.5635 - val_accuracy: 0.7135\n",
      "Epoch 12/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7257 - val_loss: 0.5630 - val_accuracy: 0.7135\n",
      "Epoch 13/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7257 - val_loss: 0.5624 - val_accuracy: 0.7135\n",
      "Epoch 14/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7240 - val_loss: 0.5619 - val_accuracy: 0.7135\n",
      "Epoch 15/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7292 - val_loss: 0.5615 - val_accuracy: 0.7135\n",
      "Epoch 16/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7326 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
      "Epoch 17/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5375 - accuracy: 0.7309 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
      "Epoch 18/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5368 - accuracy: 0.7309 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
      "Epoch 19/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7309 - val_loss: 0.5595 - val_accuracy: 0.7083\n",
      "Epoch 20/400\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.7326 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 21/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.7326 - val_loss: 0.5586 - val_accuracy: 0.7083\n",
      "Epoch 22/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5339 - accuracy: 0.7326 - val_loss: 0.5581 - val_accuracy: 0.7083\n",
      "Epoch 23/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.7326 - val_loss: 0.5576 - val_accuracy: 0.7083\n",
      "Epoch 24/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7344 - val_loss: 0.5572 - val_accuracy: 0.7083\n",
      "Epoch 25/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7326 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
      "Epoch 26/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7344 - val_loss: 0.5563 - val_accuracy: 0.7083\n",
      "Epoch 27/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5306 - accuracy: 0.7344 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
      "Epoch 28/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.7344 - val_loss: 0.5554 - val_accuracy: 0.7083\n",
      "Epoch 29/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7378 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 30/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7378 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
      "Epoch 31/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7378 - val_loss: 0.5540 - val_accuracy: 0.7083\n",
      "Epoch 32/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7378 - val_loss: 0.5536 - val_accuracy: 0.7083\n",
      "Epoch 33/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7378 - val_loss: 0.5532 - val_accuracy: 0.7083\n",
      "Epoch 34/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7378 - val_loss: 0.5528 - val_accuracy: 0.7083\n",
      "Epoch 35/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7378 - val_loss: 0.5524 - val_accuracy: 0.7083\n",
      "Epoch 36/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7378 - val_loss: 0.5520 - val_accuracy: 0.7083\n",
      "Epoch 37/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7378 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
      "Epoch 38/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.7378 - val_loss: 0.5512 - val_accuracy: 0.7083\n",
      "Epoch 39/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7396 - val_loss: 0.5508 - val_accuracy: 0.7135\n",
      "Epoch 40/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7396 - val_loss: 0.5504 - val_accuracy: 0.7135\n",
      "Epoch 41/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.7378 - val_loss: 0.5501 - val_accuracy: 0.7135\n",
      "Epoch 42/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7396 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 43/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.7378 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 44/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7396 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 45/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5197 - accuracy: 0.7396 - val_loss: 0.5486 - val_accuracy: 0.7188\n",
      "Epoch 46/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7413 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 47/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5186 - accuracy: 0.7378 - val_loss: 0.5479 - val_accuracy: 0.7188\n",
      "Epoch 48/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.7413 - val_loss: 0.5476 - val_accuracy: 0.7188\n",
      "Epoch 49/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7396 - val_loss: 0.5472 - val_accuracy: 0.7188\n",
      "Epoch 50/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7396 - val_loss: 0.5468 - val_accuracy: 0.7188\n",
      "Epoch 51/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7413 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
      "Epoch 52/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7413 - val_loss: 0.5461 - val_accuracy: 0.7188\n",
      "Epoch 53/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7413 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 54/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7448 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
      "Epoch 55/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7448 - val_loss: 0.5451 - val_accuracy: 0.7188\n",
      "Epoch 56/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7431 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
      "Epoch 57/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5133 - accuracy: 0.7431 - val_loss: 0.5445 - val_accuracy: 0.7188\n",
      "Epoch 58/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7448 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
      "Epoch 59/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7396 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 60/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7413 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
      "Epoch 61/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7413 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
      "Epoch 62/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7448 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
      "Epoch 63/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7431 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
      "Epoch 64/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7448 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 65/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7431 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
      "Epoch 66/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5090 - accuracy: 0.7431 - val_loss: 0.5416 - val_accuracy: 0.7188\n",
      "Epoch 67/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.7431 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
      "Epoch 68/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5081 - accuracy: 0.7448 - val_loss: 0.5410 - val_accuracy: 0.7188\n",
      "Epoch 69/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5076 - accuracy: 0.7431 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
      "Epoch 70/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7431 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
      "Epoch 71/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7448 - val_loss: 0.5402 - val_accuracy: 0.7188\n",
      "Epoch 72/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7448 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 73/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7448 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
      "Epoch 74/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7448 - val_loss: 0.5393 - val_accuracy: 0.7188\n",
      "Epoch 75/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7465 - val_loss: 0.5390 - val_accuracy: 0.7188\n",
      "Epoch 76/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7465 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
      "Epoch 77/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7448 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
      "Epoch 78/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5037 - accuracy: 0.7465 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 79/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7483 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 80/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7465 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 81/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7465 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 82/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7465 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 83/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.7465 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
      "Epoch 84/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7483 - val_loss: 0.5367 - val_accuracy: 0.7240\n",
      "Epoch 85/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7465 - val_loss: 0.5364 - val_accuracy: 0.7240\n",
      "Epoch 86/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7240\n",
      "Epoch 87/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5359 - val_accuracy: 0.7240\n",
      "Epoch 88/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.7500 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
      "Epoch 89/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7517 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 90/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7517 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 91/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7517 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 92/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.7517 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 93/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7517 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 94/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7517 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
      "Epoch 95/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7535 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 96/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.7535 - val_loss: 0.5338 - val_accuracy: 0.7292\n",
      "Epoch 97/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7517 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
      "Epoch 98/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7535 - val_loss: 0.5333 - val_accuracy: 0.7292\n",
      "Epoch 99/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7535 - val_loss: 0.5331 - val_accuracy: 0.7292\n",
      "Epoch 100/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7292\n",
      "Epoch 101/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7552 - val_loss: 0.5326 - val_accuracy: 0.7240\n",
      "Epoch 102/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.7552 - val_loss: 0.5324 - val_accuracy: 0.7240\n",
      "Epoch 103/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4943 - accuracy: 0.7552 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 104/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7552 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
      "Epoch 105/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.7552 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 106/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7587 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 107/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7569 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
      "Epoch 108/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7569 - val_loss: 0.5311 - val_accuracy: 0.7188\n",
      "Epoch 109/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7535 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
      "Epoch 110/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7569 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
      "Epoch 111/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7552 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
      "Epoch 112/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7535 - val_loss: 0.5303 - val_accuracy: 0.7240\n",
      "Epoch 113/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.7535 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
      "Epoch 114/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7535 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 115/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7552 - val_loss: 0.5297 - val_accuracy: 0.7240\n",
      "Epoch 116/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7552 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 117/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7552 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 118/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7569 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
      "Epoch 119/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7569 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 120/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7587 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 121/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7587 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 122/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7569 - val_loss: 0.5284 - val_accuracy: 0.7240\n",
      "Epoch 123/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7569 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 124/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7569 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 125/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7587 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
      "Epoch 126/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7587 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
      "Epoch 127/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7569 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
      "Epoch 128/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7569 - val_loss: 0.5273 - val_accuracy: 0.7240\n",
      "Epoch 129/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.7587 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
      "Epoch 130/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
      "Epoch 131/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7569 - val_loss: 0.5268 - val_accuracy: 0.7240\n",
      "Epoch 132/400\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7587 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
      "Epoch 133/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7569 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
      "Epoch 134/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7240\n",
      "Epoch 135/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7240\n",
      "Epoch 136/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7240\n",
      "Epoch 137/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7240\n",
      "Epoch 138/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7622 - val_loss: 0.5257 - val_accuracy: 0.7240\n",
      "Epoch 139/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7656 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
      "Epoch 140/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
      "Epoch 141/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 142/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7240\n",
      "Epoch 143/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
      "Epoch 144/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 145/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7240\n",
      "Epoch 146/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 147/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 148/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 149/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 150/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 151/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 152/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7691 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 153/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
      "Epoch 154/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.5234 - val_accuracy: 0.7292\n",
      "Epoch 155/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
      "Epoch 156/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7708 - val_loss: 0.5232 - val_accuracy: 0.7292\n",
      "Epoch 157/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 158/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7708 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
      "Epoch 159/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.5228 - val_accuracy: 0.7292\n",
      "Epoch 160/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
      "Epoch 161/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
      "Epoch 162/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7726 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
      "Epoch 163/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7726 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
      "Epoch 164/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7726 - val_loss: 0.5221 - val_accuracy: 0.7292\n",
      "Epoch 165/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7726 - val_loss: 0.5220 - val_accuracy: 0.7292\n",
      "Epoch 166/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 167/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.7726 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 168/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 169/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 170/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 171/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
      "Epoch 172/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
      "Epoch 173/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
      "Epoch 174/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 175/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 176/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7726 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 177/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 178/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 179/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 180/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 181/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 182/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 183/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 184/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 185/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7292\n",
      "Epoch 186/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 187/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 188/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7760 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 189/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.7760 - val_loss: 0.5193 - val_accuracy: 0.7292\n",
      "Epoch 190/400\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
      "Epoch 191/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.5191 - val_accuracy: 0.7292\n",
      "Epoch 192/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5190 - val_accuracy: 0.7292\n",
      "Epoch 193/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.5189 - val_accuracy: 0.7292\n",
      "Epoch 194/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
      "Epoch 195/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.5187 - val_accuracy: 0.7292\n",
      "Epoch 196/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.5186 - val_accuracy: 0.7292\n",
      "Epoch 197/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 198/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 199/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7760 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 200/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7760 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 201/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 202/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 203/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 204/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 205/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 206/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 207/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 208/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 209/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 210/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 211/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 212/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 213/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 214/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7292\n",
      "Epoch 215/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4704 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7292\n",
      "Epoch 216/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7292\n",
      "Epoch 217/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7812 - val_loss: 0.5167 - val_accuracy: 0.7292\n",
      "Epoch 218/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 219/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7812 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 220/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 221/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 222/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 223/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 224/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 225/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 226/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 227/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 228/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7292\n",
      "Epoch 229/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7292\n",
      "Epoch 230/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.5157 - val_accuracy: 0.7292\n",
      "Epoch 231/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
      "Epoch 232/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
      "Epoch 233/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
      "Epoch 234/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 235/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 236/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 237/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 238/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 239/400\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.7795 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 240/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 241/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 242/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 243/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 244/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 245/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 246/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 247/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 248/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 249/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
      "Epoch 250/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
      "Epoch 251/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
      "Epoch 252/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
      "Epoch 253/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
      "Epoch 254/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5141 - val_accuracy: 0.7292\n",
      "Epoch 255/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
      "Epoch 256/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
      "Epoch 257/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
      "Epoch 258/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
      "Epoch 259/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5138 - val_accuracy: 0.7292\n",
      "Epoch 260/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5137 - val_accuracy: 0.7292\n",
      "Epoch 261/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5137 - val_accuracy: 0.7292\n",
      "Epoch 262/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
      "Epoch 263/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
      "Epoch 264/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
      "Epoch 265/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
      "Epoch 266/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7830 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
      "Epoch 267/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
      "Epoch 268/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
      "Epoch 269/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 270/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 271/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
      "Epoch 272/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
      "Epoch 273/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 274/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 275/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 276/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 277/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
      "Epoch 278/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
      "Epoch 279/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
      "Epoch 280/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
      "Epoch 281/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
      "Epoch 282/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
      "Epoch 283/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
      "Epoch 284/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
      "Epoch 285/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
      "Epoch 286/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
      "Epoch 287/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
      "Epoch 288/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
      "Epoch 289/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
      "Epoch 290/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
      "Epoch 291/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7292\n",
      "Epoch 292/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7292\n",
      "Epoch 293/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
      "Epoch 294/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
      "Epoch 295/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
      "Epoch 296/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
      "Epoch 297/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
      "Epoch 298/400\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
      "Epoch 299/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
      "Epoch 300/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
      "Epoch 301/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.5116 - val_accuracy: 0.7240\n",
      "Epoch 302/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7240\n",
      "Epoch 303/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7240\n",
      "Epoch 304/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7240\n",
      "Epoch 305/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7240\n",
      "Epoch 306/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7240\n",
      "Epoch 307/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7240\n",
      "Epoch 308/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7240\n",
      "Epoch 309/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7240\n",
      "Epoch 310/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7240\n",
      "Epoch 311/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7240\n",
      "Epoch 312/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7240\n",
      "Epoch 313/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7240\n",
      "Epoch 314/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7240\n",
      "Epoch 315/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7240\n",
      "Epoch 316/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
      "Epoch 317/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
      "Epoch 318/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7240\n",
      "Epoch 319/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7240\n",
      "Epoch 320/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7240\n",
      "Epoch 321/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7240\n",
      "Epoch 322/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7188\n",
      "Epoch 323/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7188\n",
      "Epoch 324/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7188\n",
      "Epoch 325/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7188\n",
      "Epoch 326/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7188\n",
      "Epoch 327/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7188\n",
      "Epoch 328/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7188\n",
      "Epoch 329/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7188\n",
      "Epoch 330/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7188\n",
      "Epoch 331/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.5103 - val_accuracy: 0.7188\n",
      "Epoch 332/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.5103 - val_accuracy: 0.7188\n",
      "Epoch 333/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7188\n",
      "Epoch 334/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7188\n",
      "Epoch 335/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7899 - val_loss: 0.5102 - val_accuracy: 0.7188\n",
      "Epoch 336/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7188\n",
      "Epoch 337/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7188\n",
      "Epoch 338/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7188\n",
      "Epoch 339/400\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7188\n",
      "Epoch 340/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7188\n",
      "Epoch 341/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7188\n",
      "Epoch 342/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7188\n",
      "Epoch 343/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7188\n",
      "Epoch 344/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7188\n",
      "Epoch 345/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7188\n",
      "Epoch 346/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7188\n",
      "Epoch 347/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7899 - val_loss: 0.5098 - val_accuracy: 0.7188\n",
      "Epoch 348/400\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7188\n",
      "Epoch 349/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7188\n",
      "Epoch 350/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7188\n",
      "Epoch 351/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7188\n",
      "Epoch 352/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7188\n",
      "Epoch 353/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7188\n",
      "Epoch 354/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7882 - val_loss: 0.5096 - val_accuracy: 0.7188\n",
      "Epoch 355/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7188\n",
      "Epoch 356/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7188\n",
      "Epoch 357/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.5095 - val_accuracy: 0.7188\n",
      "Epoch 358/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7188\n",
      "Epoch 359/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7188\n",
      "Epoch 360/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7188\n",
      "Epoch 361/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7188\n",
      "Epoch 362/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7188\n",
      "Epoch 363/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5093 - val_accuracy: 0.7188\n",
      "Epoch 364/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7188\n",
      "Epoch 365/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7188\n",
      "Epoch 366/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7188\n",
      "Epoch 367/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5092 - val_accuracy: 0.7188\n",
      "Epoch 368/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7188\n",
      "Epoch 369/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7135\n",
      "Epoch 370/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7135\n",
      "Epoch 371/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7135\n",
      "Epoch 372/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7135\n",
      "Epoch 373/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7135\n",
      "Epoch 374/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7135\n",
      "Epoch 375/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7135\n",
      "Epoch 376/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7135\n",
      "Epoch 377/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7135\n",
      "Epoch 378/400\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7135\n",
      "Epoch 379/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7135\n",
      "Epoch 380/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7135\n",
      "Epoch 381/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7135\n",
      "Epoch 382/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7135\n",
      "Epoch 383/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7135\n",
      "Epoch 384/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7135\n",
      "Epoch 385/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7135\n",
      "Epoch 386/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7135\n",
      "Epoch 387/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4553 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7135\n",
      "Epoch 388/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7135\n",
      "Epoch 389/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7135\n",
      "Epoch 390/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7135\n",
      "Epoch 391/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7135\n",
      "Epoch 392/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7135\n",
      "Epoch 393/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7135\n",
      "Epoch 394/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7135\n",
      "Epoch 395/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7135\n",
      "Epoch 396/400\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7135\n",
      "Epoch 397/400\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7135\n",
      "Epoch 398/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7135\n",
      "Epoch 399/400\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7135\n",
      "Epoch 400/400\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=400, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19bfcfdbc70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">แบบฝึกปฏิบัติ</span>\n",
    "\n",
    "(รวม 100 คะแนน) ให้นิสิตใช้พื้นที่ต่อไปนี้ ในการเพิ่มโค้ดให้เป็นไปตามข้อกำหนดต่อไปนี้\n",
    "1. (50 คะแนน) เพิ่มเซลโค้ด เพื่อ\n",
    "   * สร้างโมเดลที่มีเลเยอร์ hidden 2 ชั้น แต่ละชั้นมี 6 โหนด\n",
    "   * ปรับโค้ดให้สามารถรับอินพุตที่มีจำนวน feature ตามข้อมูลเทรนที่จะถูกส่งเข้ามา (ปราศจากการใช้ค่าคงที่ 8 ที่ถูกระบุอยู่ในโค้ด ณ ตอนนี้)\n",
    "   * สำหรับเลเยอร์ hidden ให้ใช้ activation function เป็น \"relu\" และเลเยอร์ output เป็น \"sigmoid\"\n",
    "   * ใช้ learning rate เท่ากับ 0.003 และเทรนด้วยจำนวน 1500 epochs ส่วนสำหรับ Hyperparameter ที่เหลือให้ใช้ค่าคงเดิม\n",
    "   * วาดกราฟของค่า loss และ accuracy ด้วยทั้งชุดข้อมูล train และ test (ดังตัวอย่างในรูปนี้)\n",
    "  <img src=\"https://drive.google.com/uc?id=1GuN0KQf64rGMa4oCY2upnbOTMzWaXmbT\" style=\"height:360px\">\n",
    "2. (50 คะแนน) เพิ่มอีกเซลโค้ด เพื่อสร้างโมเดลที่มีการปรับโครงสร้างที่เหมาะสมขึ้น รวมถึงการปรับค่า Hyperparameter ต่าง ๆ เพื่อให้โมเดลใหม่ได้ผลลัพธ์ที่ดีขึ้น (โดยพิจารณาจากค่า accuracy) และในการเทรนโมเดลใหม่นี้ ห้ามมีการใช้ Early Stopping \n",
    "   * ให้วาดกราฟของค่า loss และ accuracy ของโมเดลใหม่นี้ด้วย\n",
    "   * อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 20ms/step - loss: 0.7464 - accuracy: 0.6528 - val_loss: 0.7318 - val_accuracy: 0.6458\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7391 - accuracy: 0.6528 - val_loss: 0.7263 - val_accuracy: 0.6510\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7323 - accuracy: 0.6493 - val_loss: 0.7212 - val_accuracy: 0.6510\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7258 - accuracy: 0.6510 - val_loss: 0.7164 - val_accuracy: 0.6510\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7198 - accuracy: 0.6510 - val_loss: 0.7120 - val_accuracy: 0.6510\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7142 - accuracy: 0.6510 - val_loss: 0.7077 - val_accuracy: 0.6510\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7090 - accuracy: 0.6510 - val_loss: 0.7038 - val_accuracy: 0.6510\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.6510 - val_loss: 0.7000 - val_accuracy: 0.6510\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.6510 - val_loss: 0.6964 - val_accuracy: 0.6510\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.6510 - val_loss: 0.6930 - val_accuracy: 0.6510\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6510 - val_loss: 0.6898 - val_accuracy: 0.6510\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.6510 - val_loss: 0.6868 - val_accuracy: 0.6510\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.6510 - val_loss: 0.6839 - val_accuracy: 0.6510\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.6510 - val_loss: 0.6811 - val_accuracy: 0.6510\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.6510 - val_loss: 0.6784 - val_accuracy: 0.6510\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6718 - accuracy: 0.6510 - val_loss: 0.6759 - val_accuracy: 0.6510\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.6510 - val_loss: 0.6734 - val_accuracy: 0.6510\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.6510 - val_loss: 0.6710 - val_accuracy: 0.6510\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.6510 - val_loss: 0.6686 - val_accuracy: 0.6510\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6663 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.6510 - val_loss: 0.6641 - val_accuracy: 0.6510\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6619 - val_accuracy: 0.6510\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6598 - val_accuracy: 0.6510\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6577 - val_accuracy: 0.6510\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.6510 - val_loss: 0.6556 - val_accuracy: 0.6510\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.6510 - val_loss: 0.6536 - val_accuracy: 0.6510\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.6510 - val_loss: 0.6517 - val_accuracy: 0.6510\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.6510 - val_loss: 0.6498 - val_accuracy: 0.6510\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6354 - accuracy: 0.6510 - val_loss: 0.6479 - val_accuracy: 0.6510\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6330 - accuracy: 0.6510 - val_loss: 0.6461 - val_accuracy: 0.6510\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6306 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6510\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6510\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6261 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6510\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.6510 - val_loss: 0.6392 - val_accuracy: 0.6510\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6218 - accuracy: 0.6510 - val_loss: 0.6376 - val_accuracy: 0.6510\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.6510 - val_loss: 0.6360 - val_accuracy: 0.6510\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6177 - accuracy: 0.6510 - val_loss: 0.6344 - val_accuracy: 0.6510\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.6510 - val_loss: 0.6328 - val_accuracy: 0.6510\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.6510 - val_loss: 0.6312 - val_accuracy: 0.6510\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.6510 - val_loss: 0.6296 - val_accuracy: 0.6510\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6098 - accuracy: 0.6510 - val_loss: 0.6281 - val_accuracy: 0.6510\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6079 - accuracy: 0.6510 - val_loss: 0.6265 - val_accuracy: 0.6510\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6061 - accuracy: 0.6510 - val_loss: 0.6250 - val_accuracy: 0.6510\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.6510 - val_loss: 0.6235 - val_accuracy: 0.6510\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6024 - accuracy: 0.6510 - val_loss: 0.6221 - val_accuracy: 0.6510\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6006 - accuracy: 0.6510 - val_loss: 0.6206 - val_accuracy: 0.6510\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5989 - accuracy: 0.6510 - val_loss: 0.6192 - val_accuracy: 0.6510\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.6510 - val_loss: 0.6178 - val_accuracy: 0.6510\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5955 - accuracy: 0.6493 - val_loss: 0.6164 - val_accuracy: 0.6510\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.6493 - val_loss: 0.6151 - val_accuracy: 0.6510\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5922 - accuracy: 0.6493 - val_loss: 0.6138 - val_accuracy: 0.6510\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5905 - accuracy: 0.6493 - val_loss: 0.6125 - val_accuracy: 0.6510\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5889 - accuracy: 0.6493 - val_loss: 0.6112 - val_accuracy: 0.6510\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5874 - accuracy: 0.6476 - val_loss: 0.6099 - val_accuracy: 0.6510\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.6493 - val_loss: 0.6087 - val_accuracy: 0.6510\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5843 - accuracy: 0.6510 - val_loss: 0.6074 - val_accuracy: 0.6510\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5828 - accuracy: 0.6545 - val_loss: 0.6062 - val_accuracy: 0.6510\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5813 - accuracy: 0.6510 - val_loss: 0.6049 - val_accuracy: 0.6510\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5798 - accuracy: 0.6528 - val_loss: 0.6037 - val_accuracy: 0.6562\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.6528 - val_loss: 0.6025 - val_accuracy: 0.6510\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5768 - accuracy: 0.6528 - val_loss: 0.6013 - val_accuracy: 0.6562\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.6545 - val_loss: 0.6002 - val_accuracy: 0.6562\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.6580 - val_loss: 0.5990 - val_accuracy: 0.6562\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.6562 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.6615 - val_loss: 0.5968 - val_accuracy: 0.6615\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5697 - accuracy: 0.6649 - val_loss: 0.5956 - val_accuracy: 0.6615\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5683 - accuracy: 0.6684 - val_loss: 0.5944 - val_accuracy: 0.6615\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5670 - accuracy: 0.6649 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5657 - accuracy: 0.6649 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5643 - accuracy: 0.6684 - val_loss: 0.5910 - val_accuracy: 0.6667\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5630 - accuracy: 0.6771 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.6753 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.6753 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.6788 - val_loss: 0.5865 - val_accuracy: 0.6667\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.6806 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5567 - accuracy: 0.6806 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.6840 - val_loss: 0.5834 - val_accuracy: 0.6615\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5543 - accuracy: 0.6892 - val_loss: 0.5824 - val_accuracy: 0.6615\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.6910 - val_loss: 0.5813 - val_accuracy: 0.6458\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5521 - accuracy: 0.6927 - val_loss: 0.5803 - val_accuracy: 0.6406\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.6892 - val_loss: 0.5793 - val_accuracy: 0.6458\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5498 - accuracy: 0.6875 - val_loss: 0.5784 - val_accuracy: 0.6458\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5486 - accuracy: 0.6875 - val_loss: 0.5775 - val_accuracy: 0.6510\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.6892 - val_loss: 0.5765 - val_accuracy: 0.6510\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5465 - accuracy: 0.6892 - val_loss: 0.5756 - val_accuracy: 0.6510\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.6892 - val_loss: 0.5747 - val_accuracy: 0.6510\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5444 - accuracy: 0.6892 - val_loss: 0.5739 - val_accuracy: 0.6562\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5434 - accuracy: 0.6927 - val_loss: 0.5730 - val_accuracy: 0.6562\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.6892 - val_loss: 0.5722 - val_accuracy: 0.6562\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.6892 - val_loss: 0.5714 - val_accuracy: 0.6562\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.6910 - val_loss: 0.5706 - val_accuracy: 0.6719\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5395 - accuracy: 0.6875 - val_loss: 0.5698 - val_accuracy: 0.6719\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.6858 - val_loss: 0.5691 - val_accuracy: 0.6667\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.6875 - val_loss: 0.5684 - val_accuracy: 0.6667\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.6892 - val_loss: 0.5677 - val_accuracy: 0.6667\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.6858 - val_loss: 0.5670 - val_accuracy: 0.6719\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.6910 - val_loss: 0.5663 - val_accuracy: 0.6719\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.6910 - val_loss: 0.5656 - val_accuracy: 0.6719\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.6927 - val_loss: 0.5650 - val_accuracy: 0.6719\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.6944 - val_loss: 0.5644 - val_accuracy: 0.6719\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5319 - accuracy: 0.6944 - val_loss: 0.5637 - val_accuracy: 0.6719\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.6944 - val_loss: 0.5632 - val_accuracy: 0.6719\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.6944 - val_loss: 0.5626 - val_accuracy: 0.6719\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.6944 - val_loss: 0.5620 - val_accuracy: 0.6667\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5289 - accuracy: 0.6962 - val_loss: 0.5614 - val_accuracy: 0.6719\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.6944 - val_loss: 0.5609 - val_accuracy: 0.6719\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.6962 - val_loss: 0.5603 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.6927 - val_loss: 0.5598 - val_accuracy: 0.6719\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5261 - accuracy: 0.6927 - val_loss: 0.5593 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.6910 - val_loss: 0.5588 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.6910 - val_loss: 0.5583 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5242 - accuracy: 0.6910 - val_loss: 0.5579 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5236 - accuracy: 0.6910 - val_loss: 0.5574 - val_accuracy: 0.6719\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.6892 - val_loss: 0.5569 - val_accuracy: 0.6667\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5224 - accuracy: 0.6927 - val_loss: 0.5565 - val_accuracy: 0.6667\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.6944 - val_loss: 0.5561 - val_accuracy: 0.6667\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.6979 - val_loss: 0.5556 - val_accuracy: 0.6615\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.6979 - val_loss: 0.5552 - val_accuracy: 0.6615\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.6979 - val_loss: 0.5548 - val_accuracy: 0.6615\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.6979 - val_loss: 0.5544 - val_accuracy: 0.6667\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7014 - val_loss: 0.5540 - val_accuracy: 0.6667\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.6997 - val_loss: 0.5536 - val_accuracy: 0.6667\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.6979 - val_loss: 0.5533 - val_accuracy: 0.6667\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.6979 - val_loss: 0.5528 - val_accuracy: 0.6667\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.6979 - val_loss: 0.5524 - val_accuracy: 0.6667\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.6997 - val_loss: 0.5521 - val_accuracy: 0.6667\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.6997 - val_loss: 0.5517 - val_accuracy: 0.6667\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.6979 - val_loss: 0.5513 - val_accuracy: 0.6667\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.6979 - val_loss: 0.5510 - val_accuracy: 0.6667\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.6997 - val_loss: 0.5506 - val_accuracy: 0.6719\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.6979 - val_loss: 0.5502 - val_accuracy: 0.6719\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.6979 - val_loss: 0.5499 - val_accuracy: 0.6719\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.6979 - val_loss: 0.5496 - val_accuracy: 0.6719\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.6997 - val_loss: 0.5492 - val_accuracy: 0.6719\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5129 - accuracy: 0.7066 - val_loss: 0.5489 - val_accuracy: 0.6719\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.7066 - val_loss: 0.5486 - val_accuracy: 0.6719\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7066 - val_loss: 0.5483 - val_accuracy: 0.6719\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7066 - val_loss: 0.5480 - val_accuracy: 0.6719\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7083 - val_loss: 0.5478 - val_accuracy: 0.6719\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7083 - val_loss: 0.5475 - val_accuracy: 0.6719\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.7083 - val_loss: 0.5472 - val_accuracy: 0.6771\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.7118 - val_loss: 0.5469 - val_accuracy: 0.6719\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7101 - val_loss: 0.5466 - val_accuracy: 0.6719\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7101 - val_loss: 0.5463 - val_accuracy: 0.6719\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7101 - val_loss: 0.5460 - val_accuracy: 0.6771\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7118 - val_loss: 0.5458 - val_accuracy: 0.6771\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7101 - val_loss: 0.5455 - val_accuracy: 0.6771\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.7101 - val_loss: 0.5452 - val_accuracy: 0.6823\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.7101 - val_loss: 0.5450 - val_accuracy: 0.6823\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5075 - accuracy: 0.7101 - val_loss: 0.5447 - val_accuracy: 0.6823\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7101 - val_loss: 0.5444 - val_accuracy: 0.6823\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7118 - val_loss: 0.5442 - val_accuracy: 0.6823\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.7135 - val_loss: 0.5439 - val_accuracy: 0.6823\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7153 - val_loss: 0.5437 - val_accuracy: 0.6823\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7135 - val_loss: 0.5434 - val_accuracy: 0.6875\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7153 - val_loss: 0.5432 - val_accuracy: 0.6875\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5054 - accuracy: 0.7135 - val_loss: 0.5430 - val_accuracy: 0.6875\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7135 - val_loss: 0.5427 - val_accuracy: 0.6875\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5047 - accuracy: 0.7118 - val_loss: 0.5425 - val_accuracy: 0.6875\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.7118 - val_loss: 0.5423 - val_accuracy: 0.6875\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5042 - accuracy: 0.7118 - val_loss: 0.5421 - val_accuracy: 0.6875\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7118 - val_loss: 0.5419 - val_accuracy: 0.6875\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7118 - val_loss: 0.5417 - val_accuracy: 0.6875\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5033 - accuracy: 0.7118 - val_loss: 0.5414 - val_accuracy: 0.6875\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7135 - val_loss: 0.5412 - val_accuracy: 0.6875\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7135 - val_loss: 0.5410 - val_accuracy: 0.6875\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7118 - val_loss: 0.5408 - val_accuracy: 0.6875\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5022 - accuracy: 0.7118 - val_loss: 0.5406 - val_accuracy: 0.6875\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5020 - accuracy: 0.7135 - val_loss: 0.5404 - val_accuracy: 0.6875\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7135 - val_loss: 0.5402 - val_accuracy: 0.6875\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.7118 - val_loss: 0.5400 - val_accuracy: 0.6875\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5012 - accuracy: 0.7188 - val_loss: 0.5398 - val_accuracy: 0.6875\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7188 - val_loss: 0.5396 - val_accuracy: 0.6875\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.7188 - val_loss: 0.5394 - val_accuracy: 0.6875\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7188 - val_loss: 0.5392 - val_accuracy: 0.6875\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5002 - accuracy: 0.7153 - val_loss: 0.5390 - val_accuracy: 0.6875\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7170 - val_loss: 0.5388 - val_accuracy: 0.6875\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.7170 - val_loss: 0.5386 - val_accuracy: 0.6875\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4996 - accuracy: 0.7170 - val_loss: 0.5385 - val_accuracy: 0.6875\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.7170 - val_loss: 0.5383 - val_accuracy: 0.6875\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.7170 - val_loss: 0.5381 - val_accuracy: 0.6875\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.7188 - val_loss: 0.5379 - val_accuracy: 0.6875\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7170 - val_loss: 0.5377 - val_accuracy: 0.6875\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7170 - val_loss: 0.5376 - val_accuracy: 0.6875\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.7170 - val_loss: 0.5374 - val_accuracy: 0.6875\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.7170 - val_loss: 0.5373 - val_accuracy: 0.6875\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.7153 - val_loss: 0.5371 - val_accuracy: 0.6875\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4976 - accuracy: 0.7153 - val_loss: 0.5369 - val_accuracy: 0.6875\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7170 - val_loss: 0.5368 - val_accuracy: 0.6927\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.7170 - val_loss: 0.5366 - val_accuracy: 0.6927\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4970 - accuracy: 0.7170 - val_loss: 0.5365 - val_accuracy: 0.6927\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7170 - val_loss: 0.5363 - val_accuracy: 0.6927\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.7170 - val_loss: 0.5362 - val_accuracy: 0.6927\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.7170 - val_loss: 0.5361 - val_accuracy: 0.6927\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7170 - val_loss: 0.5359 - val_accuracy: 0.6927\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.7170 - val_loss: 0.5358 - val_accuracy: 0.6927\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7205 - val_loss: 0.5356 - val_accuracy: 0.6927\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7205 - val_loss: 0.5355 - val_accuracy: 0.6927\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7205 - val_loss: 0.5354 - val_accuracy: 0.6927\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4952 - accuracy: 0.7240 - val_loss: 0.5352 - val_accuracy: 0.6927\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4950 - accuracy: 0.7240 - val_loss: 0.5351 - val_accuracy: 0.6927\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4948 - accuracy: 0.7240 - val_loss: 0.5350 - val_accuracy: 0.6927\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.7257 - val_loss: 0.5348 - val_accuracy: 0.6979\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7309 - val_loss: 0.5347 - val_accuracy: 0.6979\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7344 - val_loss: 0.5346 - val_accuracy: 0.6979\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7344 - val_loss: 0.5344 - val_accuracy: 0.6979\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4939 - accuracy: 0.7344 - val_loss: 0.5343 - val_accuracy: 0.6979\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7344 - val_loss: 0.5342 - val_accuracy: 0.6979\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7326 - val_loss: 0.5341 - val_accuracy: 0.6979\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7344 - val_loss: 0.5340 - val_accuracy: 0.6979\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7344 - val_loss: 0.5338 - val_accuracy: 0.6979\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7344 - val_loss: 0.5337 - val_accuracy: 0.6979\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7344 - val_loss: 0.5336 - val_accuracy: 0.6979\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7344 - val_loss: 0.5335 - val_accuracy: 0.6979\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7361 - val_loss: 0.5334 - val_accuracy: 0.6979\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7361 - val_loss: 0.5333 - val_accuracy: 0.6979\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7361 - val_loss: 0.5332 - val_accuracy: 0.6927\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7361 - val_loss: 0.5331 - val_accuracy: 0.6927\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7361 - val_loss: 0.5330 - val_accuracy: 0.6927\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.7361 - val_loss: 0.5329 - val_accuracy: 0.6927\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.7378 - val_loss: 0.5328 - val_accuracy: 0.6927\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7378 - val_loss: 0.5327 - val_accuracy: 0.6927\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4911 - accuracy: 0.7396 - val_loss: 0.5326 - val_accuracy: 0.6979\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.7396 - val_loss: 0.5325 - val_accuracy: 0.6979\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.7413 - val_loss: 0.5324 - val_accuracy: 0.6979\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7413 - val_loss: 0.5323 - val_accuracy: 0.6979\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7413 - val_loss: 0.5322 - val_accuracy: 0.6979\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7431 - val_loss: 0.5321 - val_accuracy: 0.6979\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.7448 - val_loss: 0.5320 - val_accuracy: 0.6979\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.7413 - val_loss: 0.5319 - val_accuracy: 0.6979\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7465 - val_loss: 0.5318 - val_accuracy: 0.6979\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7465 - val_loss: 0.5318 - val_accuracy: 0.6979\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.7448 - val_loss: 0.5317 - val_accuracy: 0.6979\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7483 - val_loss: 0.5316 - val_accuracy: 0.6979\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7448 - val_loss: 0.5315 - val_accuracy: 0.6979\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7448 - val_loss: 0.5314 - val_accuracy: 0.6979\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.7465 - val_loss: 0.5314 - val_accuracy: 0.6979\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.7465 - val_loss: 0.5313 - val_accuracy: 0.6979\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.6979\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4888 - accuracy: 0.7465 - val_loss: 0.5312 - val_accuracy: 0.6979\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.7465 - val_loss: 0.5311 - val_accuracy: 0.6979\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7465 - val_loss: 0.5310 - val_accuracy: 0.6927\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7465 - val_loss: 0.5309 - val_accuracy: 0.6979\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.7465 - val_loss: 0.5309 - val_accuracy: 0.6979\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7483 - val_loss: 0.5308 - val_accuracy: 0.6979\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7517 - val_loss: 0.5307 - val_accuracy: 0.6979\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7500 - val_loss: 0.5307 - val_accuracy: 0.6979\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7517 - val_loss: 0.5306 - val_accuracy: 0.6927\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7500 - val_loss: 0.5305 - val_accuracy: 0.6927\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7500 - val_loss: 0.5304 - val_accuracy: 0.6927\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.6927\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4873 - accuracy: 0.7500 - val_loss: 0.5303 - val_accuracy: 0.6927\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.6927\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7517 - val_loss: 0.5301 - val_accuracy: 0.6979\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7535 - val_loss: 0.5300 - val_accuracy: 0.6979\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.7500 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.7500 - val_loss: 0.5298 - val_accuracy: 0.6979\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7517 - val_loss: 0.5298 - val_accuracy: 0.6979\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.7500 - val_loss: 0.5297 - val_accuracy: 0.6979\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.7535 - val_loss: 0.5296 - val_accuracy: 0.7031\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.7535 - val_loss: 0.5295 - val_accuracy: 0.7031\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7552 - val_loss: 0.5294 - val_accuracy: 0.7031\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7552 - val_loss: 0.5293 - val_accuracy: 0.7031\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7552 - val_loss: 0.5292 - val_accuracy: 0.7031\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.7552 - val_loss: 0.5291 - val_accuracy: 0.7031\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7552 - val_loss: 0.5290 - val_accuracy: 0.7031\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.7552 - val_loss: 0.5289 - val_accuracy: 0.7031\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7535 - val_loss: 0.5288 - val_accuracy: 0.7031\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7535 - val_loss: 0.5287 - val_accuracy: 0.7031\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7535 - val_loss: 0.5286 - val_accuracy: 0.7031\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7552 - val_loss: 0.5285 - val_accuracy: 0.7031\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7552 - val_loss: 0.5284 - val_accuracy: 0.7031\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7552 - val_loss: 0.5283 - val_accuracy: 0.7031\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7552 - val_loss: 0.5282 - val_accuracy: 0.7031\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7552 - val_loss: 0.5281 - val_accuracy: 0.7031\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7552 - val_loss: 0.5280 - val_accuracy: 0.7031\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7552 - val_loss: 0.5280 - val_accuracy: 0.7031\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7552 - val_loss: 0.5279 - val_accuracy: 0.7031\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7552 - val_loss: 0.5278 - val_accuracy: 0.7031\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4834 - accuracy: 0.7552 - val_loss: 0.5277 - val_accuracy: 0.7031\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7569 - val_loss: 0.5276 - val_accuracy: 0.7031\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7569 - val_loss: 0.5275 - val_accuracy: 0.7031\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7587 - val_loss: 0.5274 - val_accuracy: 0.7031\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.7604 - val_loss: 0.5273 - val_accuracy: 0.7031\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.5273 - val_accuracy: 0.7031\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7622 - val_loss: 0.5272 - val_accuracy: 0.7031\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7031\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7031\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.7622 - val_loss: 0.5269 - val_accuracy: 0.7031\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7622 - val_loss: 0.5268 - val_accuracy: 0.7031\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.5268 - val_accuracy: 0.7031\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7622 - val_loss: 0.5267 - val_accuracy: 0.7031\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7604 - val_loss: 0.5266 - val_accuracy: 0.7031\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4814 - accuracy: 0.7604 - val_loss: 0.5265 - val_accuracy: 0.7031\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4813 - accuracy: 0.7604 - val_loss: 0.5265 - val_accuracy: 0.7031\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7604 - val_loss: 0.5264 - val_accuracy: 0.7031\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7031\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7031\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7031\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.7604 - val_loss: 0.5262 - val_accuracy: 0.7031\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7031\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7083\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 0.5259 - val_accuracy: 0.7083\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.5259 - val_accuracy: 0.7083\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7639 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7604 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.7604 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7604 - val_loss: 0.5255 - val_accuracy: 0.7135\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7604 - val_loss: 0.5255 - val_accuracy: 0.7135\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7622 - val_loss: 0.5254 - val_accuracy: 0.7135\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7135\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7135\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7135\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7639 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7639 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.7639 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.7639 - val_loss: 0.5249 - val_accuracy: 0.7135\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7639 - val_loss: 0.5249 - val_accuracy: 0.7135\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5248 - val_accuracy: 0.7135\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7135\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7135\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.7708 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7708 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.7708 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.5233 - val_accuracy: 0.7188\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.5231 - val_accuracy: 0.7188\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.5230 - val_accuracy: 0.7188\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.5229 - val_accuracy: 0.7188\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7188\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5226 - val_accuracy: 0.7188\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.5226 - val_accuracy: 0.7188\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.5224 - val_accuracy: 0.7188\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7188\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.5222 - val_accuracy: 0.7188\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.5222 - val_accuracy: 0.7188\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7795 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7795 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7812 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7865 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7240\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7865 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7882 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.7882 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7882 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7899 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7899 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7917 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.7917 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7917 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4667 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.7899 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4657 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7934 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7917 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7917 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7917 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7917 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7917 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7917 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4645 - accuracy: 0.7917 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4644 - accuracy: 0.7917 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7917 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7934 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4641 - accuracy: 0.7917 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7934 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7917 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7934 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.7934 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7934 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7934 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7934 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7934 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.7934 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7934 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7934 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7934 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4624 - accuracy: 0.7934 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4621 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7917 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4619 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4616 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4615 - accuracy: 0.7917 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7917 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7917 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7917 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7917 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7899 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4605 - accuracy: 0.7899 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7899 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4601 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7899 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7899 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7899 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4592 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7899 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7917 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4563 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7917 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4556 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4554 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4547 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7899 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7934 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4527 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4520 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4514 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7986 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4500 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4496 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4482 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4479 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4446 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4444 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4423 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4422 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4420 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4419 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_2.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500, batch_size=32)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19cccabe950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2.history[\"accuracy\"],'r', marker='.', label=\"Accuracy\")\n",
    "ax.plot(run_hist_2.history[\"loss\"],'b', marker='.', label=\"Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(5, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.7121 - accuracy: 0.3872 - val_loss: 0.7023 - val_accuracy: 0.4375\n",
      "Epoch 2/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6892 - accuracy: 0.5139 - val_loss: 0.6842 - val_accuracy: 0.5833\n",
      "Epoch 3/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6731 - accuracy: 0.6979 - val_loss: 0.6705 - val_accuracy: 0.7240\n",
      "Epoch 4/500\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.6609 - accuracy: 0.7413 - val_loss: 0.6603 - val_accuracy: 0.7292\n",
      "Epoch 5/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6515 - accuracy: 0.7448 - val_loss: 0.6518 - val_accuracy: 0.7240\n",
      "Epoch 6/500\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.6437 - accuracy: 0.7344 - val_loss: 0.6447 - val_accuracy: 0.7135\n",
      "Epoch 7/500\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.6370 - accuracy: 0.7222 - val_loss: 0.6385 - val_accuracy: 0.7188\n",
      "Epoch 8/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.6311 - accuracy: 0.7188 - val_loss: 0.6328 - val_accuracy: 0.7188\n",
      "Epoch 9/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.7153 - val_loss: 0.6275 - val_accuracy: 0.7188\n",
      "Epoch 10/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6202 - accuracy: 0.7222 - val_loss: 0.6224 - val_accuracy: 0.7188\n",
      "Epoch 11/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.6150 - accuracy: 0.7222 - val_loss: 0.6175 - val_accuracy: 0.7240\n",
      "Epoch 12/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.6099 - accuracy: 0.7240 - val_loss: 0.6126 - val_accuracy: 0.7292\n",
      "Epoch 13/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.6047 - accuracy: 0.7274 - val_loss: 0.6076 - val_accuracy: 0.7448\n",
      "Epoch 14/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5995 - accuracy: 0.7326 - val_loss: 0.6026 - val_accuracy: 0.7448\n",
      "Epoch 15/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5942 - accuracy: 0.7448 - val_loss: 0.5975 - val_accuracy: 0.7552\n",
      "Epoch 16/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5889 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
      "Epoch 17/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.7517 - val_loss: 0.5870 - val_accuracy: 0.7448\n",
      "Epoch 18/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.7552 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
      "Epoch 19/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.5723 - accuracy: 0.7604 - val_loss: 0.5764 - val_accuracy: 0.7552\n",
      "Epoch 20/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5666 - accuracy: 0.7604 - val_loss: 0.5710 - val_accuracy: 0.7604\n",
      "Epoch 21/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5610 - accuracy: 0.7656 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 22/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.7656 - val_loss: 0.5604 - val_accuracy: 0.7448\n",
      "Epoch 23/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5497 - accuracy: 0.7622 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
      "Epoch 24/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5441 - accuracy: 0.7674 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
      "Epoch 25/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5387 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 26/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7708 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
      "Epoch 27/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5284 - accuracy: 0.7760 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
      "Epoch 28/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.5238 - accuracy: 0.7760 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 29/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5191 - accuracy: 0.7743 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 30/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7760 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 31/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 32/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.7778 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 33/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 34/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 35/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7500\n",
      "Epoch 36/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 37/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 38/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 39/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 40/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4813 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 41/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7344\n",
      "Epoch 42/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 43/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
      "Epoch 44/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 45/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 46/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 47/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 48/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7344\n",
      "Epoch 49/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7344\n",
      "Epoch 50/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7292\n",
      "Epoch 51/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.7882 - val_loss: 0.4949 - val_accuracy: 0.7292\n",
      "Epoch 52/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4948 - val_accuracy: 0.7292\n",
      "Epoch 53/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7292\n",
      "Epoch 54/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7899 - val_loss: 0.4946 - val_accuracy: 0.7292\n",
      "Epoch 55/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4576 - accuracy: 0.7899 - val_loss: 0.4946 - val_accuracy: 0.7292\n",
      "Epoch 56/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.7882 - val_loss: 0.4947 - val_accuracy: 0.7292\n",
      "Epoch 57/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4557 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7292\n",
      "Epoch 58/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.4949 - val_accuracy: 0.7292\n",
      "Epoch 59/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7899 - val_loss: 0.4950 - val_accuracy: 0.7292\n",
      "Epoch 60/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7292\n",
      "Epoch 61/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7344\n",
      "Epoch 62/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7344\n",
      "Epoch 63/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7344\n",
      "Epoch 64/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
      "Epoch 65/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
      "Epoch 66/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
      "Epoch 67/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7344\n",
      "Epoch 68/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7344\n",
      "Epoch 69/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7344\n",
      "Epoch 70/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4966 - val_accuracy: 0.7344\n",
      "Epoch 71/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.4969 - val_accuracy: 0.7344\n",
      "Epoch 72/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7344\n",
      "Epoch 73/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7344\n",
      "Epoch 74/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7344\n",
      "Epoch 75/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7344\n",
      "Epoch 76/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
      "Epoch 77/500\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
      "Epoch 78/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
      "Epoch 79/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
      "Epoch 80/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 81/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
      "Epoch 82/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
      "Epoch 83/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
      "Epoch 84/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
      "Epoch 85/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 86/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 87/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
      "Epoch 88/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
      "Epoch 89/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
      "Epoch 90/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 91/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 92/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 93/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 94/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 95/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 96/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 97/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 98/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 99/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 100/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 101/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 102/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 103/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 104/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 105/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 106/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 107/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 108/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 109/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
      "Epoch 110/500\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.4363 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 111/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 112/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 113/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 114/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 115/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4352 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 116/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 117/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 118/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 119/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 120/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 121/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 122/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
      "Epoch 123/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 124/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7448\n",
      "Epoch 125/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
      "Epoch 126/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 127/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
      "Epoch 128/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
      "Epoch 129/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7396\n",
      "Epoch 130/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
      "Epoch 131/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 132/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
      "Epoch 133/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
      "Epoch 134/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
      "Epoch 135/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
      "Epoch 136/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
      "Epoch 137/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
      "Epoch 138/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
      "Epoch 139/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 140/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
      "Epoch 141/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7292\n",
      "Epoch 142/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
      "Epoch 143/500\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 144/500\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 145/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 146/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
      "Epoch 147/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
      "Epoch 148/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 149/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
      "Epoch 150/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
      "Epoch 151/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 152/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7292\n",
      "Epoch 153/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7292\n",
      "Epoch 154/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 155/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
      "Epoch 156/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7344\n",
      "Epoch 157/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7344\n",
      "Epoch 158/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7344\n",
      "Epoch 159/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5037 - val_accuracy: 0.7292\n",
      "Epoch 160/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
      "Epoch 161/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
      "Epoch 162/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
      "Epoch 163/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7344\n",
      "Epoch 164/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
      "Epoch 165/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7344\n",
      "Epoch 166/500\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5047 - val_accuracy: 0.7344\n",
      "Epoch 167/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7344\n",
      "Epoch 168/500\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7344\n",
      "Epoch 169/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7344\n",
      "Epoch 170/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7344\n",
      "Epoch 171/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7344\n",
      "Epoch 172/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7344\n",
      "Epoch 173/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 174/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 175/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
      "Epoch 176/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
      "Epoch 177/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
      "Epoch 178/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
      "Epoch 179/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
      "Epoch 180/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 181/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 182/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
      "Epoch 183/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
      "Epoch 184/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
      "Epoch 185/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7344\n",
      "Epoch 186/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7344\n",
      "Epoch 187/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
      "Epoch 188/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
      "Epoch 189/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 190/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 191/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 192/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 193/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 194/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 195/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 196/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 197/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 198/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 199/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 200/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 201/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 202/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 203/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 204/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 205/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 206/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 207/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 208/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 209/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 210/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 211/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 212/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 213/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 214/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 215/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 216/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 217/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 218/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 219/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 220/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 221/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 222/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5227 - val_accuracy: 0.7292\n",
      "Epoch 223/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
      "Epoch 224/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
      "Epoch 225/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 226/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 227/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 228/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8073 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
      "Epoch 229/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
      "Epoch 230/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
      "Epoch 231/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8073 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 232/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4138 - accuracy: 0.8108 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 233/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8108 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 234/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4131 - accuracy: 0.8108 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
      "Epoch 235/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
      "Epoch 236/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 237/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
      "Epoch 238/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
      "Epoch 239/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
      "Epoch 240/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8108 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
      "Epoch 241/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 242/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8056 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
      "Epoch 243/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 244/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
      "Epoch 245/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
      "Epoch 246/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 247/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8108 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 248/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 249/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 250/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 251/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4100 - accuracy: 0.8090 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 252/500\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 253/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 254/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8090 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 255/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 256/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8108 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 257/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8108 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 258/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 259/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 260/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 261/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8108 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 262/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4084 - accuracy: 0.8108 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
      "Epoch 263/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 264/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 265/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 266/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 267/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 268/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.5311 - val_accuracy: 0.7448\n",
      "Epoch 269/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 270/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 271/500\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 272/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 273/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 274/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 275/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 276/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8142 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 277/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8142 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 278/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8142 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 279/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 280/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8160 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 281/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 282/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 283/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 284/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 285/500\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 286/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8108 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 287/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 288/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 289/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8073 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 290/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8108 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 291/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4043 - accuracy: 0.8142 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 292/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 293/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4039 - accuracy: 0.8142 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 294/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 295/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 296/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4037 - accuracy: 0.8160 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 297/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8160 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 298/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 299/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8142 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 300/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8160 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 301/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8142 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 302/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
      "Epoch 303/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8160 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 304/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 305/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8177 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 306/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8142 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 307/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8142 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 308/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 309/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
      "Epoch 310/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
      "Epoch 311/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4015 - accuracy: 0.8177 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 312/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7448\n",
      "Epoch 313/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 314/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4011 - accuracy: 0.8194 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 315/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 316/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
      "Epoch 317/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 318/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
      "Epoch 319/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8212 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
      "Epoch 320/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4006 - accuracy: 0.8177 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
      "Epoch 321/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 322/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 323/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 324/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8247 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
      "Epoch 325/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5395 - val_accuracy: 0.7448\n",
      "Epoch 326/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.4001 - accuracy: 0.8229 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
      "Epoch 327/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
      "Epoch 328/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8160 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 329/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3997 - accuracy: 0.8212 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 330/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8229 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
      "Epoch 331/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 332/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3994 - accuracy: 0.8177 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
      "Epoch 333/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8194 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
      "Epoch 334/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 335/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 336/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 337/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8247 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 338/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 339/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8212 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 340/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8212 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 341/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8194 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
      "Epoch 342/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8247 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
      "Epoch 343/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
      "Epoch 344/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 345/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8177 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
      "Epoch 346/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8264 - val_loss: 0.5428 - val_accuracy: 0.7448\n",
      "Epoch 347/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
      "Epoch 348/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 349/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8142 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
      "Epoch 350/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 351/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8299 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
      "Epoch 352/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 353/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8247 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
      "Epoch 354/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8264 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 355/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 356/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8212 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 357/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3965 - accuracy: 0.8247 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 358/500\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.3965 - accuracy: 0.8247 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 359/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 360/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8194 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
      "Epoch 361/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8247 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
      "Epoch 362/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8229 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
      "Epoch 363/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3964 - accuracy: 0.8281 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
      "Epoch 364/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8212 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
      "Epoch 365/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8264 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 366/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 0.5480 - val_accuracy: 0.7396\n",
      "Epoch 367/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8212 - val_loss: 0.5478 - val_accuracy: 0.7396\n",
      "Epoch 368/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3958 - accuracy: 0.8247 - val_loss: 0.5480 - val_accuracy: 0.7396\n",
      "Epoch 369/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8247 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
      "Epoch 370/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
      "Epoch 371/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8247 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
      "Epoch 372/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8247 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
      "Epoch 373/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8194 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 374/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3953 - accuracy: 0.8264 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
      "Epoch 375/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
      "Epoch 376/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 377/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8247 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
      "Epoch 378/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8229 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
      "Epoch 379/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8229 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 380/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
      "Epoch 381/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
      "Epoch 382/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
      "Epoch 383/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5520 - val_accuracy: 0.7292\n",
      "Epoch 384/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 385/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
      "Epoch 386/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3949 - accuracy: 0.8229 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 387/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3937 - accuracy: 0.8247 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 388/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
      "Epoch 389/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3936 - accuracy: 0.8229 - val_loss: 0.5520 - val_accuracy: 0.7292\n",
      "Epoch 390/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
      "Epoch 391/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3939 - accuracy: 0.8247 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
      "Epoch 392/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5527 - val_accuracy: 0.7188\n",
      "Epoch 393/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 394/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8194 - val_loss: 0.5529 - val_accuracy: 0.7188\n",
      "Epoch 395/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
      "Epoch 396/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8247 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
      "Epoch 397/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
      "Epoch 398/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3929 - accuracy: 0.8177 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
      "Epoch 399/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
      "Epoch 400/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8229 - val_loss: 0.5548 - val_accuracy: 0.7188\n",
      "Epoch 401/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8247 - val_loss: 0.5560 - val_accuracy: 0.7240\n",
      "Epoch 402/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8247 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
      "Epoch 403/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3925 - accuracy: 0.8299 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
      "Epoch 404/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8281 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
      "Epoch 405/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8247 - val_loss: 0.5550 - val_accuracy: 0.7188\n",
      "Epoch 406/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8229 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
      "Epoch 407/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8229 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
      "Epoch 408/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3928 - accuracy: 0.8264 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
      "Epoch 409/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8247 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
      "Epoch 410/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8247 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
      "Epoch 411/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8247 - val_loss: 0.5570 - val_accuracy: 0.7240\n",
      "Epoch 412/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8264 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
      "Epoch 413/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3921 - accuracy: 0.8333 - val_loss: 0.5587 - val_accuracy: 0.7240\n",
      "Epoch 414/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8212 - val_loss: 0.5567 - val_accuracy: 0.7188\n",
      "Epoch 415/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3921 - accuracy: 0.8316 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
      "Epoch 416/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8194 - val_loss: 0.5587 - val_accuracy: 0.7240\n",
      "Epoch 417/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3921 - accuracy: 0.8247 - val_loss: 0.5589 - val_accuracy: 0.7240\n",
      "Epoch 418/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3919 - accuracy: 0.8229 - val_loss: 0.5584 - val_accuracy: 0.7240\n",
      "Epoch 419/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3919 - accuracy: 0.8316 - val_loss: 0.5596 - val_accuracy: 0.7240\n",
      "Epoch 420/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8229 - val_loss: 0.5591 - val_accuracy: 0.7188\n",
      "Epoch 421/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8247 - val_loss: 0.5596 - val_accuracy: 0.7240\n",
      "Epoch 422/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8229 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
      "Epoch 423/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5604 - val_accuracy: 0.7240\n",
      "Epoch 424/500\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8247 - val_loss: 0.5601 - val_accuracy: 0.7240\n",
      "Epoch 425/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8264 - val_loss: 0.5597 - val_accuracy: 0.7188\n",
      "Epoch 426/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8212 - val_loss: 0.5603 - val_accuracy: 0.7188\n",
      "Epoch 427/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.5610 - val_accuracy: 0.7188\n",
      "Epoch 428/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3908 - accuracy: 0.8264 - val_loss: 0.5603 - val_accuracy: 0.7188\n",
      "Epoch 429/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5616 - val_accuracy: 0.7188\n",
      "Epoch 430/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8299 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
      "Epoch 431/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5624 - val_accuracy: 0.7240\n",
      "Epoch 432/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3906 - accuracy: 0.8229 - val_loss: 0.5622 - val_accuracy: 0.7240\n",
      "Epoch 433/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8333 - val_loss: 0.5627 - val_accuracy: 0.7240\n",
      "Epoch 434/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8247 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 435/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8229 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 436/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8299 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
      "Epoch 437/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5630 - val_accuracy: 0.7188\n",
      "Epoch 438/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3906 - accuracy: 0.8281 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 439/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8316 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
      "Epoch 440/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.8281 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
      "Epoch 441/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8299 - val_loss: 0.5650 - val_accuracy: 0.7240\n",
      "Epoch 442/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3907 - accuracy: 0.8247 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 443/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3901 - accuracy: 0.8281 - val_loss: 0.5660 - val_accuracy: 0.7188\n",
      "Epoch 444/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8281 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
      "Epoch 445/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8247 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
      "Epoch 446/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3901 - accuracy: 0.8264 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
      "Epoch 447/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3899 - accuracy: 0.8299 - val_loss: 0.5664 - val_accuracy: 0.7188\n",
      "Epoch 448/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5653 - val_accuracy: 0.7188\n",
      "Epoch 449/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8281 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
      "Epoch 450/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8281 - val_loss: 0.5648 - val_accuracy: 0.7135\n",
      "Epoch 451/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8264 - val_loss: 0.5665 - val_accuracy: 0.7240\n",
      "Epoch 452/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5677 - val_accuracy: 0.7240\n",
      "Epoch 453/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8281 - val_loss: 0.5672 - val_accuracy: 0.7240\n",
      "Epoch 454/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 455/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5683 - val_accuracy: 0.7240\n",
      "Epoch 456/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8351 - val_loss: 0.5704 - val_accuracy: 0.7292\n",
      "Epoch 457/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5710 - val_accuracy: 0.7292\n",
      "Epoch 458/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8281 - val_loss: 0.5710 - val_accuracy: 0.7292\n",
      "Epoch 459/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3888 - accuracy: 0.8212 - val_loss: 0.5697 - val_accuracy: 0.7135\n",
      "Epoch 460/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8299 - val_loss: 0.5708 - val_accuracy: 0.7240\n",
      "Epoch 461/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8264 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
      "Epoch 462/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3883 - accuracy: 0.8247 - val_loss: 0.5699 - val_accuracy: 0.7188\n",
      "Epoch 463/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3887 - accuracy: 0.8368 - val_loss: 0.5702 - val_accuracy: 0.7135\n",
      "Epoch 464/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8316 - val_loss: 0.5722 - val_accuracy: 0.7240\n",
      "Epoch 465/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3890 - accuracy: 0.8264 - val_loss: 0.5708 - val_accuracy: 0.7240\n",
      "Epoch 466/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3893 - accuracy: 0.8299 - val_loss: 0.5707 - val_accuracy: 0.7135\n",
      "Epoch 467/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8247 - val_loss: 0.5709 - val_accuracy: 0.7135\n",
      "Epoch 468/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3893 - accuracy: 0.8247 - val_loss: 0.5713 - val_accuracy: 0.7240\n",
      "Epoch 469/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3892 - accuracy: 0.8299 - val_loss: 0.5720 - val_accuracy: 0.7292\n",
      "Epoch 470/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8247 - val_loss: 0.5728 - val_accuracy: 0.7240\n",
      "Epoch 471/500\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.3889 - accuracy: 0.8299 - val_loss: 0.5728 - val_accuracy: 0.7188\n",
      "Epoch 472/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3884 - accuracy: 0.8351 - val_loss: 0.5714 - val_accuracy: 0.7135\n",
      "Epoch 473/500\n",
      "58/58 [==============================] - 1s 8ms/step - loss: 0.3884 - accuracy: 0.8316 - val_loss: 0.5742 - val_accuracy: 0.7240\n",
      "Epoch 474/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3887 - accuracy: 0.8316 - val_loss: 0.5732 - val_accuracy: 0.7240\n",
      "Epoch 475/500\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.3879 - accuracy: 0.8316 - val_loss: 0.5750 - val_accuracy: 0.7240\n",
      "Epoch 476/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8281 - val_loss: 0.5721 - val_accuracy: 0.7188\n",
      "Epoch 477/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3885 - accuracy: 0.8281 - val_loss: 0.5727 - val_accuracy: 0.7188\n",
      "Epoch 478/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5750 - val_accuracy: 0.7240\n",
      "Epoch 479/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8281 - val_loss: 0.5741 - val_accuracy: 0.7240\n",
      "Epoch 480/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8281 - val_loss: 0.5741 - val_accuracy: 0.7240\n",
      "Epoch 481/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3878 - accuracy: 0.8281 - val_loss: 0.5750 - val_accuracy: 0.7240\n",
      "Epoch 482/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8316 - val_loss: 0.5737 - val_accuracy: 0.7240\n",
      "Epoch 483/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8299 - val_loss: 0.5750 - val_accuracy: 0.7240\n",
      "Epoch 484/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.5748 - val_accuracy: 0.7240\n",
      "Epoch 485/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8281 - val_loss: 0.5762 - val_accuracy: 0.7240\n",
      "Epoch 486/500\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.3873 - accuracy: 0.8264 - val_loss: 0.5784 - val_accuracy: 0.7240\n",
      "Epoch 487/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3879 - accuracy: 0.8247 - val_loss: 0.5756 - val_accuracy: 0.7240\n",
      "Epoch 488/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8299 - val_loss: 0.5754 - val_accuracy: 0.7240\n",
      "Epoch 489/500\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5766 - val_accuracy: 0.7240\n",
      "Epoch 490/500\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8316 - val_loss: 0.5761 - val_accuracy: 0.7240\n",
      "Epoch 491/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8351 - val_loss: 0.5789 - val_accuracy: 0.7292\n",
      "Epoch 492/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5764 - val_accuracy: 0.7240\n",
      "Epoch 493/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3882 - accuracy: 0.8264 - val_loss: 0.5760 - val_accuracy: 0.7188\n",
      "Epoch 494/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3877 - accuracy: 0.8264 - val_loss: 0.5752 - val_accuracy: 0.7135\n",
      "Epoch 495/500\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8316 - val_loss: 0.5773 - val_accuracy: 0.7240\n",
      "Epoch 496/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3879 - accuracy: 0.8247 - val_loss: 0.5766 - val_accuracy: 0.7240\n",
      "Epoch 497/500\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3875 - accuracy: 0.8299 - val_loss: 0.5765 - val_accuracy: 0.7240\n",
      "Epoch 498/500\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3878 - accuracy: 0.8281 - val_loss: 0.5786 - val_accuracy: 0.7292\n",
      "Epoch 499/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8316 - val_loss: 0.5785 - val_accuracy: 0.7240\n",
      "Epoch 500/500\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8264 - val_loss: 0.5779 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_3.compile(optimizer=SGD(learning_rate=0.005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_3 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500, batch_size=10)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19cd5a91d20>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_3.history[\"accuracy\"],'r', marker='.', label=\"Accuracy\")\n",
    "ax.plot(run_hist_3.history[\"loss\"],'b', marker='.', label=\"Loss\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
